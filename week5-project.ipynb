{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project: StackOverflow assistant bot\n",
    "\n",
    "Congratulations on coming this far and solving the programming assignments! In this final project, we will combine everything we have learned about Natural Language Processing to construct a *dialogue chat bot*, which will be able to:\n",
    "* answer programming-related questions (using StackOverflow dataset);\n",
    "* chit-chat and simulate dialogue on all non programming-related questions.\n",
    "\n",
    "For a chit-chat mode we will use a pre-trained neural network engine available from [ChatterBot](https://github.com/gunthercox/ChatterBot).\n",
    "Those who aim at honor certificates for our course or are just curious, will train their own models for chit-chat.\n",
    "![](https://imgs.xkcd.com/comics/twitter_bot.png)\n",
    "©[xkcd](https://xkcd.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "To detect *intent* of users questions we will need two text collections:\n",
    "- `tagged_posts.tsv` — StackOverflow posts, tagged with one programming language (*positive samples*).\n",
    "- `dialogues.tsv` — dialogue phrases from movie subtitles (*negative samples*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3321ff2f330405f8e37c2da76a6e5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18012894), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0847ef331d2b4f468bb8ff88dae640da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=145677870), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from common.download_utils import download_project_resources\n",
    "\n",
    "download_project_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those questions, that have programming-related intent, we will proceed as follow predict programming language (only one tag per question allowed here) and rank candidates within the tag using embeddings.\n",
    "For the ranking part, you will need:\n",
    "- `word_embeddings.tsv` — word embeddings, that you  trained with StarSpace in the 3rd assignment. It's not a problem if you didn't do it, because we can offer an alternative solution for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of this notebook, you should obtain the following new objects that you will then use in the running bot:\n",
    "\n",
    "- `intent_recognizer.pkl` — intent recognition model;\n",
    "- `tag_classifier.pkl` — programming language classification model;\n",
    "- `tfidf_vectorizer.pkl` — vectorizer used during training;\n",
    "- `thread_embeddings_by_tags` — folder with thread embeddings, arranged by tags.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions will be reused by this notebook and the scripts, so we put them into *utils.py* file. Don't forget to open it and fill in the gaps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../week3/starSpaceEmbeddings.tsv.tsv .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   65505 starspace_embeddings.tsv\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l starspace_embeddings.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Intent and language recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to write a bot, which will not only **answer programming-related questions**, but also will be able to **maintain a dialogue**. We would also like to detect the *intent* of the user from the question (we could have had a 'Question answering mode' check-box in the bot, but it wouldn't fun at all, would it?). So the first thing we need to do is to **distinguish programming-related questions from general ones**.\n",
    "\n",
    "It would also be good to predict which programming language a particular question referees to. By doing so, we will speed up question search by a factor of the number of languages (10 here), and exercise our *text classification* skill a bit. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first assignment (Predict tags on StackOverflow with linear models), you have already learnt how to preprocess texts and do TF-IDF tranformations. Reuse your code here. In addition, you will also need to [dump](https://docs.python.org/3/library/pickle.html#pickle.dump) the TF-IDF vectorizer with pickle to use it later in the running bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "#     print(text)\n",
    "    text = text.lower() # lowercase text\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, \" \", text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = re.sub(BAD_SYMBOLS_RE, \"\", text)# delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = \" \".join([w for w in text.split(\" \") if w != \"\" and w not in STOPWORDS])  # delete stopwords from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_test, vectorizer_path):\n",
    "    \"\"\"Performs TF-IDF transformation and dumps the model.\"\"\"\n",
    "    \n",
    "    # Train a vectorizer on X_train data.\n",
    "    # Transform X_train and X_test data.\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(0, 1), token_pattern= '(\\S+)')\n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    # Pickle the trained vectorizer to 'vectorizer_path'\n",
    "    # Don't forget to open the file in writing bytes mode.\n",
    "\n",
    "    pickle.dump(tfidf_vectorizer, open( vectorizer_path, 'wb'), protocol=3)\n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load examples of two classes. Use a subsample of stackoverflow data to balance the classes. You will need the full data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 200000\n",
    "\n",
    "dialogue_df = pd.read_csv('data/dialogues.tsv', sep='\\t').sample(sample_size, random_state=0)\n",
    "stackoverflow_df = pd.read_csv('data/tagged_posts.tsv', sep='\\t').sample(sample_size, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how the data look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82925</th>\n",
       "      <td>Donna, you are a muffin.</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48774</th>\n",
       "      <td>He was here last night till about two o'clock....</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55394</th>\n",
       "      <td>All right, then make an appointment with her s...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90806</th>\n",
       "      <td>Hey, what is this-an interview? We're supposed...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107758</th>\n",
       "      <td>Yeah. He's just a friend of mine I was trying ...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       tag\n",
       "82925                            Donna, you are a muffin.  dialogue\n",
       "48774   He was here last night till about two o'clock....  dialogue\n",
       "55394   All right, then make an appointment with her s...  dialogue\n",
       "90806   Hey, what is this-an interview? We're supposed...  dialogue\n",
       "107758  Yeah. He's just a friend of mine I was trying ...  dialogue"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2168983</th>\n",
       "      <td>43837842</td>\n",
       "      <td>Efficient Algorithm to compose valid expressio...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084095</th>\n",
       "      <td>15747223</td>\n",
       "      <td>Why does this basic thread program fail with C...</td>\n",
       "      <td>c_cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049020</th>\n",
       "      <td>15189594</td>\n",
       "      <td>Link to scroll to top not working</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200466</th>\n",
       "      <td>3273927</td>\n",
       "      <td>Is it possible to implement ping on windows ph...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200249</th>\n",
       "      <td>17684551</td>\n",
       "      <td>GLSL normal mapping issue</td>\n",
       "      <td>c_cpp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          post_id                                              title  \\\n",
       "2168983  43837842  Efficient Algorithm to compose valid expressio...   \n",
       "1084095  15747223  Why does this basic thread program fail with C...   \n",
       "1049020  15189594                  Link to scroll to top not working   \n",
       "200466    3273927  Is it possible to implement ping on windows ph...   \n",
       "1200249  17684551                          GLSL normal mapping issue   \n",
       "\n",
       "                tag  \n",
       "2168983      python  \n",
       "1084095       c_cpp  \n",
       "1049020  javascript  \n",
       "200466           c#  \n",
       "1200249       c_cpp  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackoverflow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply *text_prepare* function to preprocess the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import text_prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82925                              Donna, you are a muffin.\n",
       "48774     He was here last night till about two o'clock....\n",
       "55394     All right, then make an appointment with her s...\n",
       "90806     Hey, what is this-an interview? We're supposed...\n",
       "107758    Yeah. He's just a friend of mine I was trying ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82925                                          donna muffin\n",
       "48774     last night till two oclock hear really got stu...\n",
       "55394                            right make appointment see\n",
       "90806             hey thisan interview supposed making love\n",
       "107758                     yeah hes friend mine trying help\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_df['text'].apply(text_prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_df['text'] = dialogue_df['text'].apply(text_prepare)\n",
    "stackoverflow_df['title'] = stackoverflow_df['title'].apply(text_prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82925                                          donna muffin\n",
       "48774     last night till two oclock hear really got stu...\n",
       "55394                            right make appointment see\n",
       "90806             hey thisan interview supposed making love\n",
       "107758                     yeah hes friend mine trying help\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do a binary classification on TF-IDF representations of texts. Labels will be either `dialogue` for general questions or `stackoverflow` for programming-related questions. First, prepare the data for this task:\n",
    "- concatenate `dialogue` and `stackoverflow` examples into one sample\n",
    "- split it into train and test in proportion 9:1, use *random_state=0* for reproducibility\n",
    "- transform it into TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 360000, test size = 40000\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([dialogue_df['text'].values, stackoverflow_df['title'].values])\n",
    "y = ['dialogue'] * dialogue_df.shape[0] + ['stackoverflow'] * stackoverflow_df.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0 )\n",
    "print('Train size = {}, test size = {}'.format(len(X_train), len(X_test)))\n",
    "\n",
    "X_train_tfidf, X_test_tfidf = tfidf_features(X_train, X_test, vectorizer_path=RESOURCE_PATH['TFIDF_VECTORIZER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the **intent recognizer** using LogisticRegression on the train set with the following parameters: *penalty='l2'*, *C=10*, *random_state=0*. Print out the accuracy on the test set to check whether everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cab/anaconda3/envs/py3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################\n",
    "\n",
    "intent_recognizer = LogisticRegression(penalty='l2', C=10, random_state=0)\n",
    "intent_recognizer.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.991725\n"
     ]
    }
   ],
   "source": [
    "# Check test accuracy.\n",
    "y_test_pred = intent_recognizer.predict(X_test_tfidf)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print('Test accuracy = {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the classifier to use it in the running bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(intent_recognizer, open(RESOURCE_PATH['INTENT_RECOGNIZER'], 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming language classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train one more classifier for the programming-related questions. It will predict exactly one tag (=programming language) and will be also based on Logistic Regression with TF-IDF features. \n",
    "\n",
    "First, let us prepare the data for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stackoverflow_df['title'].values\n",
    "y = stackoverflow_df['tag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 160000, test size = 40000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print('Train size = {}, test size = {}'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us reuse the TF-IDF vectorizer that we have already created above. It should not make a huge difference which data was used to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(RESOURCE_PATH['TFIDF_VECTORIZER'], 'rb'))\n",
    "\n",
    "X_train_tfidf, X_test_tfidf = vectorizer.transform(X_train), vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the **tag classifier** using OneVsRestClassifier wrapper over LogisticRegression. Use the following parameters: *penalty='l2'*, *C=5*, *random_state=0*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cab/anaconda3/envs/py3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################\n",
    "\n",
    "tag_classifier = OneVsRestClassifier(LogisticRegression(penalty='l2', C=5, random_state=0))\n",
    "tag_classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.797325\n"
     ]
    }
   ],
   "source": [
    "# Check test accuracy.\n",
    "y_test_pred = tag_classifier.predict(X_test_tfidf)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print('Test accuracy = {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the classifier to use it in the running bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tag_classifier, open(RESOURCE_PATH['TAG_CLASSIFIER'], 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Ranking  questions with embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a relevant answer (a thread from StackOverflow) on a question you will use vector representations to calculate similarity between the question and existing threads. We already had `question_to_vec` function from the assignment 3, which can create such a representation based on word vectors. \n",
    "\n",
    "However, it would be costly to compute such a representation for all possible answers in *online mode* of the bot (e.g. when bot is running and answering questions from many users). This is the reason why you will create a *database* with pre-computed representations. These representations will be arranged by non-overlaping tags (programming languages), so that the search of the answer can be performed only within one tag each time. This will make our bot even more efficient and allow not to store all the database in RAM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load StarSpace embeddings which were trained on Stack Overflow posts. These embeddings were trained in *supervised mode* for duplicates detection on the same corpus that is used in search. We can account on that these representations will allow us to find closely related answers for a question. \n",
    "\n",
    "If for some reasons you didn't train StarSpace embeddings in the assignment 3, you can use [pre-trained word vectors](https://code.google.com/archive/p/word2vec/) from Google. All instructions about how to work with these vectors were provided in the same assignment. However, we highly recommend to use StartSpace's embeddings, because it contains more appropriate embeddings. If you chose to use Google's embeddings, delete the words, which is not in Stackoverflow data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogues.tsv            starspace_embeddings.tsv tagged_posts.tsv\r\n"
     ]
    }
   ],
   "source": [
    "! ls data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embeddings_path):\n",
    "    \"\"\"Loads pre-trained word embeddings from tsv file.\n",
    "\n",
    "    Args:\n",
    "      embeddings_path - path to the embeddings file.\n",
    "\n",
    "    Returns:\n",
    "      embeddings - dict mapping words to vectors;\n",
    "      embeddings_dim - dimension of the vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hint: you have already implemented a similar routine in the 3rd assignment.\n",
    "    # Note that here you also need to know the dimension of the loaded embeddings.\n",
    "    # When you load the embeddings, use numpy.float32 type as dtype\n",
    "\n",
    "    ########################\n",
    "    #### YOUR CODE HERE ####\n",
    "    ########################\n",
    "    starspace_embeddings = {}\n",
    "    for line in open(embeddings_path, 'r'):\n",
    "        word, *embs = line.strip().split('\\t')\n",
    "        starspace_embeddings[word] = np.array(list(map(float, embs)),  dtype=np.float32)\n",
    "\n",
    "    return starspace_embeddings, starspace_embeddings[next(iter(starspace_embeddings))].shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_vec(question, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        embeddings: dict where the key is a word and a value is its' embedding\n",
    "        dim: size of the representation\n",
    "\n",
    "        result: vector representation for the question\n",
    "    \"\"\"\n",
    "    vectors = [embeddings[w] for w in question.split(' ') if w in embeddings]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(np.vstack(vectors), axis=0)\n",
    "    else:\n",
    "        return np.zeros((dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "starspace_embeddings, embeddings_dim = load_embeddings('data/starspace_embeddings.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to precompute representations for all possible answers, we need to load the whole posts dataset, unlike we did for the intent classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_csv('data/tagged_posts.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Calculate age in C#</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Filling a DataSet or DataTable from a LINQ que...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>Reliable timer in a console application</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>Best way to allow plugins for a PHP application</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>How do I get a distinct, ordered list of names...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                              title  tag\n",
       "0        9                                Calculate age in C#   c#\n",
       "1       16  Filling a DataSet or DataTable from a LINQ que...   c#\n",
       "2       39            Reliable timer in a console application   c#\n",
       "3       42    Best way to allow plugins for a PHP application  php\n",
       "4       59  How do I get a distinct, ordered list of names...   c#"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34226</th>\n",
       "      <td>759216</td>\n",
       "      <td>implementation of composition and aggregation ...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                                              title tag\n",
       "34226   759216  implementation of composition and aggregation ...  c#"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df[posts_df['post_id'] == 759216]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the distribution of posts for programming languages (tags) and find the most common ones. \n",
    "You might want to use pandas [groupby](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html) and [count](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.count.html) methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_tag = posts_df[[\"title\", \"tag\"]].groupby('tag').count()['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c#', 394451),\n",
       " ('c_cpp', 281300),\n",
       " ('java', 383456),\n",
       " ('javascript', 375867),\n",
       " ('php', 321752),\n",
       " ('python', 208607),\n",
       " ('r', 36359),\n",
       " ('ruby', 99930),\n",
       " ('swift', 34809),\n",
       " ('vb', 35044)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(tag, count) for tag, count in counts_by_tag.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each `tag` you need to create two data structures, which will serve as online search index:\n",
    "* `tag_post_ids` — a list of post_ids with shape `(counts_by_tag[tag],)`. It will be needed to show the title and link to the thread;\n",
    "* `tag_vectors` — a matrix with shape `(counts_by_tag[tag], embeddings_dim)` where embeddings for each answer are stored.\n",
    "\n",
    "Implement the code which will calculate the mentioned structures and dump it to files. It should take several minutes to compute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(RESOURCE_PATH['THREAD_EMBEDDINGS_FOLDER'], exist_ok=True)\n",
    "\n",
    "for tag, count in counts_by_tag.items():\n",
    "    tag_posts = posts_df[posts_df['tag'] == tag]\n",
    "    \n",
    "    tag_post_ids = [p for (i, p) in posts_df[posts_df['tag'] == tag]['post_id'].items()]\n",
    "    \n",
    "    tag_vectors = np.zeros((count, embeddings_dim), dtype=np.float32)\n",
    "    for i, title in enumerate(tag_posts['title']):\n",
    "        tag_vectors[i, :] = question_to_vec(title, starspace_embeddings, embeddings_dim)\n",
    "\n",
    "    # Dump post ids and vectors to a file.\n",
    "    filename = os.path.join(RESOURCE_PATH['THREAD_EMBEDDINGS_FOLDER'], os.path.normpath('%s.pkl' % tag))\n",
    "    pickle.dump((tag_post_ids, tag_vectors), open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'How to access the last value in a vector?'),\n",
       " (1, 'Explain the quantile() function in R'),\n",
       " (2, 'Sample Code for R?'),\n",
       " (3, 'What are some good books, web resources, and projects for learning R?'),\n",
       " (4, 'Thinking in Vectors with R')]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, title) for i, title in enumerate(posts_df[posts_df['tag'] == 'r'].head()['title'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      9\n",
       "1     16\n",
       "2     39\n",
       "4     59\n",
       "5    109\n",
       "Name: post_id, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df[posts_df['tag'] == 'c#'].head()['post_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 16,\n",
       " 39,\n",
       " 59,\n",
       " 109,\n",
       " 174,\n",
       " 260,\n",
       " 289,\n",
       " 482,\n",
       " 601,\n",
       " 650,\n",
       " 709,\n",
       " 752,\n",
       " 832,\n",
       " 930,\n",
       " 944,\n",
       " 1010,\n",
       " 1241,\n",
       " 1535,\n",
       " 1760,\n",
       " 1836,\n",
       " 1848,\n",
       " 1898,\n",
       " 1936,\n",
       " 1994,\n",
       " 1995,\n",
       " 2154,\n",
       " 2209,\n",
       " 2214,\n",
       " 2250,\n",
       " 2256,\n",
       " 2267,\n",
       " 2483,\n",
       " 2527,\n",
       " 2780,\n",
       " 2785,\n",
       " 2871,\n",
       " 2872,\n",
       " 2874,\n",
       " 2987,\n",
       " 3213,\n",
       " 3234,\n",
       " 3713,\n",
       " 3725,\n",
       " 3903,\n",
       " 4157,\n",
       " 4221,\n",
       " 4227,\n",
       " 4363,\n",
       " 4432,\n",
       " 4556,\n",
       " 4610,\n",
       " 4612,\n",
       " 4664,\n",
       " 4849,\n",
       " 4850,\n",
       " 4913,\n",
       " 4930,\n",
       " 5179,\n",
       " 5194,\n",
       " 5269,\n",
       " 5307,\n",
       " 5694,\n",
       " 5706,\n",
       " 5787,\n",
       " 6184,\n",
       " 6406,\n",
       " 6623,\n",
       " 6681,\n",
       " 6890,\n",
       " 6973,\n",
       " 7015,\n",
       " 7074,\n",
       " 7095,\n",
       " 7367,\n",
       " 7586,\n",
       " 7719,\n",
       " 7990,\n",
       " 7991,\n",
       " 8042,\n",
       " 8223,\n",
       " 8348,\n",
       " 8546,\n",
       " 8566,\n",
       " 8604,\n",
       " 8691,\n",
       " 8800,\n",
       " 8893,\n",
       " 8896,\n",
       " 8987,\n",
       " 9173,\n",
       " 9303,\n",
       " 9314,\n",
       " 9472,\n",
       " 9486,\n",
       " 9508,\n",
       " 9666,\n",
       " 9673,\n",
       " 9734,\n",
       " 9805,\n",
       " 10071,\n",
       " 10098,\n",
       " 10412,\n",
       " 10456,\n",
       " 10458,\n",
       " 10531,\n",
       " 10855,\n",
       " 10901,\n",
       " 10905,\n",
       " 10915,\n",
       " 10949,\n",
       " 11194,\n",
       " 11267,\n",
       " 11288,\n",
       " 11345,\n",
       " 11423,\n",
       " 11516,\n",
       " 11632,\n",
       " 11762,\n",
       " 11767,\n",
       " 11804,\n",
       " 11806,\n",
       " 12045,\n",
       " 12051,\n",
       " 12135,\n",
       " 12306,\n",
       " 12671,\n",
       " 12702,\n",
       " 12716,\n",
       " 13060,\n",
       " 13087,\n",
       " 13170,\n",
       " 13217,\n",
       " 13353,\n",
       " 13524,\n",
       " 13615,\n",
       " 13731,\n",
       " 13765,\n",
       " 14029,\n",
       " 14359,\n",
       " 14375,\n",
       " 14453,\n",
       " 14505,\n",
       " 14731,\n",
       " 14775,\n",
       " 14934,\n",
       " 14943,\n",
       " 15023,\n",
       " 15066,\n",
       " 15102,\n",
       " 15142,\n",
       " 15204,\n",
       " 15272,\n",
       " 15716,\n",
       " 15734,\n",
       " 15744,\n",
       " 15828,\n",
       " 15954,\n",
       " 16100,\n",
       " 16110,\n",
       " 16114,\n",
       " 16199,\n",
       " 16306,\n",
       " 16340,\n",
       " 16610,\n",
       " 16611,\n",
       " 16747,\n",
       " 16833,\n",
       " 16998,\n",
       " 17032,\n",
       " 17170,\n",
       " 17532,\n",
       " 17576,\n",
       " 17612,\n",
       " 17725,\n",
       " 17772,\n",
       " 17878,\n",
       " 18097,\n",
       " 18421,\n",
       " 18448,\n",
       " 18505,\n",
       " 18533,\n",
       " 18584,\n",
       " 18585,\n",
       " 18661,\n",
       " 18705,\n",
       " 18757,\n",
       " 18765,\n",
       " 19147,\n",
       " 19353,\n",
       " 19746,\n",
       " 19933,\n",
       " 19953,\n",
       " 20061,\n",
       " 20084,\n",
       " 20185,\n",
       " 20267,\n",
       " 20298,\n",
       " 20465,\n",
       " 20467,\n",
       " 20762,\n",
       " 20797,\n",
       " 20814,\n",
       " 21078,\n",
       " 21280,\n",
       " 21288,\n",
       " 21461,\n",
       " 21987,\n",
       " 22012,\n",
       " 22084,\n",
       " 22269,\n",
       " 22322,\n",
       " 22356,\n",
       " 22623,\n",
       " 22879,\n",
       " 22979,\n",
       " 22988,\n",
       " 23250,\n",
       " 23370,\n",
       " 23391,\n",
       " 23787,\n",
       " 24200,\n",
       " 24252,\n",
       " 24262,\n",
       " 24315,\n",
       " 24644,\n",
       " 25007,\n",
       " 25158,\n",
       " 25200,\n",
       " 25241,\n",
       " 25297,\n",
       " 25343,\n",
       " 25349,\n",
       " 25376,\n",
       " 25458,\n",
       " 25803,\n",
       " 26020,\n",
       " 26196,\n",
       " 26233,\n",
       " 26354,\n",
       " 26355,\n",
       " 26369,\n",
       " 26522,\n",
       " 26570,\n",
       " 26719,\n",
       " 26733,\n",
       " 26809,\n",
       " 26816,\n",
       " 26857,\n",
       " 26877,\n",
       " 26903,\n",
       " 27455,\n",
       " 27570,\n",
       " 27674,\n",
       " 27711,\n",
       " 27726,\n",
       " 27757,\n",
       " 28092,\n",
       " 28637,\n",
       " 28642,\n",
       " 28756,\n",
       " 28768,\n",
       " 28858,\n",
       " 29141,\n",
       " 29346,\n",
       " 29436,\n",
       " 29482,\n",
       " 29654,\n",
       " 29664,\n",
       " 29686,\n",
       " 29696,\n",
       " 29731,\n",
       " 29845,\n",
       " 29980,\n",
       " 30004,\n",
       " 30080,\n",
       " 30430,\n",
       " 30653,\n",
       " 31007,\n",
       " 31053,\n",
       " 31215,\n",
       " 31238,\n",
       " 31408,\n",
       " 31410,\n",
       " 31424,\n",
       " 31498,\n",
       " 31534,\n",
       " 31567,\n",
       " 31581,\n",
       " 31708,\n",
       " 31794,\n",
       " 31871,\n",
       " 31885,\n",
       " 31930,\n",
       " 32000,\n",
       " 32034,\n",
       " 32103,\n",
       " 32173,\n",
       " 32260,\n",
       " 32343,\n",
       " 32395,\n",
       " 32397,\n",
       " 32401,\n",
       " 32433,\n",
       " 32612,\n",
       " 32637,\n",
       " 32649,\n",
       " 32664,\n",
       " 32717,\n",
       " 32718,\n",
       " 32747,\n",
       " 32824,\n",
       " 32937,\n",
       " 33063,\n",
       " 33115,\n",
       " 33250,\n",
       " 33265,\n",
       " 33761,\n",
       " 34093,\n",
       " 34128,\n",
       " 34183,\n",
       " 34505,\n",
       " 34516,\n",
       " 34809,\n",
       " 34852,\n",
       " 34913,\n",
       " 35007,\n",
       " 35103,\n",
       " 35167,\n",
       " 35219,\n",
       " 35479,\n",
       " 35537,\n",
       " 35614,\n",
       " 35893,\n",
       " 35914,\n",
       " 36014,\n",
       " 36326,\n",
       " 36350,\n",
       " 36477,\n",
       " 36748,\n",
       " 37248,\n",
       " 37317,\n",
       " 37324,\n",
       " 37591,\n",
       " 37882,\n",
       " 37932,\n",
       " 38010,\n",
       " 38039,\n",
       " 38308,\n",
       " 38510,\n",
       " 38670,\n",
       " 38756,\n",
       " 38789,\n",
       " 38960,\n",
       " 38998,\n",
       " 39003,\n",
       " 39112,\n",
       " 39116,\n",
       " 39447,\n",
       " 39727,\n",
       " 39735,\n",
       " 39903,\n",
       " 40022,\n",
       " 40054,\n",
       " 40075,\n",
       " 40090,\n",
       " 40107,\n",
       " 40132,\n",
       " 40161,\n",
       " 40352,\n",
       " 40465,\n",
       " 40535,\n",
       " 40680,\n",
       " 40814,\n",
       " 40962,\n",
       " 40999,\n",
       " 41159,\n",
       " 41319,\n",
       " 41397,\n",
       " 41405,\n",
       " 41407,\n",
       " 41449,\n",
       " 41568,\n",
       " 41792,\n",
       " 41842,\n",
       " 41908,\n",
       " 41994,\n",
       " 42071,\n",
       " 42150,\n",
       " 42212,\n",
       " 42272,\n",
       " 42505,\n",
       " 42627,\n",
       " 42852,\n",
       " 42966,\n",
       " 43021,\n",
       " 43051,\n",
       " 43126,\n",
       " 43224,\n",
       " 43500,\n",
       " 43511,\n",
       " 43536,\n",
       " 43711,\n",
       " 43738,\n",
       " 44161,\n",
       " 44220,\n",
       " 44270,\n",
       " 44288,\n",
       " 44404,\n",
       " 44408,\n",
       " 44421,\n",
       " 44504,\n",
       " 44656,\n",
       " 44771,\n",
       " 44777,\n",
       " 44787,\n",
       " 44905,\n",
       " 44942,\n",
       " 44980,\n",
       " 44989,\n",
       " 44999,\n",
       " 45132,\n",
       " 45293,\n",
       " 45437,\n",
       " 45475,\n",
       " 45481,\n",
       " 45604,\n",
       " 45705,\n",
       " 45779,\n",
       " 45988,\n",
       " 46030,\n",
       " 46130,\n",
       " 46282,\n",
       " 46394,\n",
       " 46489,\n",
       " 46855,\n",
       " 46860,\n",
       " 46909,\n",
       " 47003,\n",
       " 47089,\n",
       " 47262,\n",
       " 47533,\n",
       " 47752,\n",
       " 47833,\n",
       " 47838,\n",
       " 48087,\n",
       " 48271,\n",
       " 48278,\n",
       " 48307,\n",
       " 48340,\n",
       " 48356,\n",
       " 48432,\n",
       " 48680,\n",
       " 49147,\n",
       " 49166,\n",
       " 49194,\n",
       " 49214,\n",
       " 49302,\n",
       " 49461,\n",
       " 49507,\n",
       " 49809,\n",
       " 50153,\n",
       " 50251,\n",
       " 50332,\n",
       " 50386,\n",
       " 50518,\n",
       " 50539,\n",
       " 50684,\n",
       " 50702,\n",
       " 50704,\n",
       " 51113,\n",
       " 51126,\n",
       " 51129,\n",
       " 51269,\n",
       " 51342,\n",
       " 51586,\n",
       " 51645,\n",
       " 51654,\n",
       " 51700,\n",
       " 51741,\n",
       " 51782,\n",
       " 51793,\n",
       " 51898,\n",
       " 51964,\n",
       " 52312,\n",
       " 52313,\n",
       " 52449,\n",
       " 52797,\n",
       " 52927,\n",
       " 52952,\n",
       " 53086,\n",
       " 53102,\n",
       " 53395,\n",
       " 53404,\n",
       " 53417,\n",
       " 53435,\n",
       " 53597,\n",
       " 53602,\n",
       " 53649,\n",
       " 53652,\n",
       " 53844,\n",
       " 53961,\n",
       " 54207,\n",
       " 54222,\n",
       " 54227,\n",
       " 54522,\n",
       " 54758,\n",
       " 54789,\n",
       " 54833,\n",
       " 54851,\n",
       " 54963,\n",
       " 54991,\n",
       " 55101,\n",
       " 55147,\n",
       " 55203,\n",
       " 55270,\n",
       " 55360,\n",
       " 55411,\n",
       " 55482,\n",
       " 55502,\n",
       " 55517,\n",
       " 55828,\n",
       " 55843,\n",
       " 55860,\n",
       " 55963,\n",
       " 55978,\n",
       " 56078,\n",
       " 56121,\n",
       " 56313,\n",
       " 56443,\n",
       " 56692,\n",
       " 56698,\n",
       " 56729,\n",
       " 56767,\n",
       " 57010,\n",
       " 57020,\n",
       " 57094,\n",
       " 57350,\n",
       " 57383,\n",
       " 57439,\n",
       " 57557,\n",
       " 57609,\n",
       " 57615,\n",
       " 57701,\n",
       " 57804,\n",
       " 57839,\n",
       " 57840,\n",
       " 57849,\n",
       " 57921,\n",
       " 57947,\n",
       " 57987,\n",
       " 58035,\n",
       " 58230,\n",
       " 58300,\n",
       " 58380,\n",
       " 58744,\n",
       " 58910,\n",
       " 59166,\n",
       " 59217,\n",
       " 59422,\n",
       " 59479,\n",
       " 59547,\n",
       " 59590,\n",
       " 59893,\n",
       " 59986,\n",
       " 60032,\n",
       " 60100,\n",
       " 60151,\n",
       " 60199,\n",
       " 60293,\n",
       " 60573,\n",
       " 60652,\n",
       " 60683,\n",
       " 60785,\n",
       " 60788,\n",
       " 60859,\n",
       " 61110,\n",
       " 61143,\n",
       " 61480,\n",
       " 61733,\n",
       " 61850,\n",
       " 61861,\n",
       " 61914,\n",
       " 61953,\n",
       " 62219,\n",
       " 62365,\n",
       " 62606,\n",
       " 62625,\n",
       " 62771,\n",
       " 62776,\n",
       " 62987,\n",
       " 63008,\n",
       " 63517,\n",
       " 63546,\n",
       " 63556,\n",
       " 63671,\n",
       " 63694,\n",
       " 63960,\n",
       " 63974,\n",
       " 64041,\n",
       " 64046,\n",
       " 64139,\n",
       " 64272,\n",
       " 64581,\n",
       " 64645,\n",
       " 64813,\n",
       " 65199,\n",
       " 65351,\n",
       " 65364,\n",
       " 65687,\n",
       " 65749,\n",
       " 65969,\n",
       " 66012,\n",
       " 66117,\n",
       " 66421,\n",
       " 66475,\n",
       " 66479,\n",
       " 66622,\n",
       " 66635,\n",
       " 66893,\n",
       " 66921,\n",
       " 67063,\n",
       " 67200,\n",
       " 67366,\n",
       " 67370,\n",
       " 67457,\n",
       " 67492,\n",
       " 67676,\n",
       " 67761,\n",
       " 67879,\n",
       " 67929,\n",
       " 67937,\n",
       " 67959,\n",
       " 68084,\n",
       " 68578,\n",
       " 68598,\n",
       " 68750,\n",
       " 69230,\n",
       " 69296,\n",
       " 69352,\n",
       " 69748,\n",
       " 69753,\n",
       " 69761,\n",
       " 70004,\n",
       " 70272,\n",
       " 70303,\n",
       " 70405,\n",
       " 70602,\n",
       " 70685,\n",
       " 70742,\n",
       " 71031,\n",
       " 71077,\n",
       " 71149,\n",
       " 71257,\n",
       " 71374,\n",
       " 71440,\n",
       " 71932,\n",
       " 72048,\n",
       " 72121,\n",
       " 72176,\n",
       " 72198,\n",
       " 72264,\n",
       " 72275,\n",
       " 72360,\n",
       " 72515,\n",
       " 72580,\n",
       " 72626,\n",
       " 72913,\n",
       " 73024,\n",
       " 73039,\n",
       " 73051,\n",
       " 73198,\n",
       " 73227,\n",
       " 73385,\n",
       " 73484,\n",
       " 73713,\n",
       " 73775,\n",
       " 73879,\n",
       " 73883,\n",
       " 73950,\n",
       " 74019,\n",
       " 74032,\n",
       " 74100,\n",
       " 74148,\n",
       " 74224,\n",
       " 74471,\n",
       " 74514,\n",
       " 74616,\n",
       " 74880,\n",
       " 75076,\n",
       " 75123,\n",
       " 75282,\n",
       " 75777,\n",
       " 75978,\n",
       " 76206,\n",
       " 76781,\n",
       " 76964,\n",
       " 77082,\n",
       " 77632,\n",
       " 77683,\n",
       " 78161,\n",
       " 78233,\n",
       " 78282,\n",
       " 78351,\n",
       " 78536,\n",
       " 78548,\n",
       " 78847,\n",
       " 79111,\n",
       " 79126,\n",
       " 79197,\n",
       " 79215,\n",
       " 79445,\n",
       " 79533,\n",
       " 79594,\n",
       " 79693,\n",
       " 79736,\n",
       " 80067,\n",
       " 80234,\n",
       " 80247,\n",
       " 80347,\n",
       " 80593,\n",
       " 80645,\n",
       " 80766,\n",
       " 81052,\n",
       " 81067,\n",
       " 81071,\n",
       " 81305,\n",
       " 81347,\n",
       " 81406,\n",
       " 81552,\n",
       " 81674,\n",
       " 81784,\n",
       " 82058,\n",
       " 82093,\n",
       " 82319,\n",
       " 82365,\n",
       " 82409,\n",
       " 82442,\n",
       " 82483,\n",
       " 82632,\n",
       " 82788,\n",
       " 82847,\n",
       " 82881,\n",
       " 82908,\n",
       " 82943,\n",
       " 83130,\n",
       " 83152,\n",
       " 83232,\n",
       " 83471,\n",
       " 83553,\n",
       " 83749,\n",
       " 83777,\n",
       " 83840,\n",
       " 83945,\n",
       " 84034,\n",
       " 84102,\n",
       " 84164,\n",
       " 84449,\n",
       " 84587,\n",
       " 84855,\n",
       " 84860,\n",
       " 84968,\n",
       " 85137,\n",
       " 85139,\n",
       " 85147,\n",
       " 85282,\n",
       " 85392,\n",
       " 85404,\n",
       " 85513,\n",
       " 85569,\n",
       " 85588,\n",
       " 85702,\n",
       " 85724,\n",
       " 85925,\n",
       " 86096,\n",
       " 86292,\n",
       " 86413,\n",
       " 86444,\n",
       " 86458,\n",
       " 86477,\n",
       " 86563,\n",
       " 86660,\n",
       " 86696,\n",
       " 86726,\n",
       " 86766,\n",
       " 86905,\n",
       " 86947,\n",
       " 87023,\n",
       " 87071,\n",
       " 87134,\n",
       " 87222,\n",
       " 87386,\n",
       " 87459,\n",
       " 87514,\n",
       " 87576,\n",
       " 87621,\n",
       " 87795,\n",
       " 87970,\n",
       " 88030,\n",
       " 88181,\n",
       " 88359,\n",
       " 88361,\n",
       " 88403,\n",
       " 88490,\n",
       " 88682,\n",
       " 88791,\n",
       " 88950,\n",
       " 89149,\n",
       " 89203,\n",
       " 89245,\n",
       " 89950,\n",
       " 90037,\n",
       " 90117,\n",
       " 90511,\n",
       " 90553,\n",
       " 90560,\n",
       " 90572,\n",
       " 90578,\n",
       " 90652,\n",
       " 90662,\n",
       " 90697,\n",
       " 90751,\n",
       " 90871,\n",
       " 90976,\n",
       " 91108,\n",
       " 91127,\n",
       " 91232,\n",
       " 91234,\n",
       " 91362,\n",
       " 91511,\n",
       " 91563,\n",
       " 91617,\n",
       " 91745,\n",
       " 91747,\n",
       " 91778,\n",
       " 91831,\n",
       " 91933,\n",
       " 92008,\n",
       " 92035,\n",
       " 92114,\n",
       " 92434,\n",
       " 92514,\n",
       " 92515,\n",
       " 92592,\n",
       " 92728,\n",
       " 92820,\n",
       " 92860,\n",
       " 92869,\n",
       " 93018,\n",
       " 93335,\n",
       " 93455,\n",
       " 93472,\n",
       " 93583,\n",
       " 93654,\n",
       " 93743,\n",
       " 93811,\n",
       " 93832,\n",
       " 93983,\n",
       " 93989,\n",
       " 94171,\n",
       " 94274,\n",
       " 94305,\n",
       " 94342,\n",
       " 94456,\n",
       " 94884,\n",
       " 95005,\n",
       " 95074,\n",
       " 95098,\n",
       " 95120,\n",
       " 95379,\n",
       " 95547,\n",
       " 95651,\n",
       " 95683,\n",
       " 95850,\n",
       " 95895,\n",
       " 95954,\n",
       " 96054,\n",
       " 96218,\n",
       " 96276,\n",
       " 96732,\n",
       " 96837,\n",
       " 97092,\n",
       " 97097,\n",
       " 97193,\n",
       " 97283,\n",
       " 97312,\n",
       " 97324,\n",
       " 97329,\n",
       " 97385,\n",
       " 97391,\n",
       " 97505,\n",
       " 97520,\n",
       " 97565,\n",
       " 97590,\n",
       " 97598,\n",
       " 97646,\n",
       " 98196,\n",
       " 98426,\n",
       " 98559,\n",
       " 98774,\n",
       " 99271,\n",
       " 99642,\n",
       " 99651,\n",
       " 99653,\n",
       " 99686,\n",
       " 99732,\n",
       " 99790,\n",
       " 99869,\n",
       " 100045,\n",
       " 100068,\n",
       " 100070,\n",
       " 100081,\n",
       " 100104,\n",
       " 100235,\n",
       " 100236,\n",
       " 100247,\n",
       " 100291,\n",
       " 100358,\n",
       " 100411,\n",
       " 100533,\n",
       " 100691,\n",
       " 100824,\n",
       " 100851,\n",
       " 100854,\n",
       " 100919,\n",
       " 101125,\n",
       " 101145,\n",
       " 101162,\n",
       " 101265,\n",
       " 101708,\n",
       " 101825,\n",
       " 102082,\n",
       " 102163,\n",
       " 102213,\n",
       " 102283,\n",
       " 102437,\n",
       " 102614,\n",
       " 102623,\n",
       " 102956,\n",
       " 103006,\n",
       " 103092,\n",
       " 103177,\n",
       " 103532,\n",
       " 103556,\n",
       " 104063,\n",
       " 104097,\n",
       " 104133,\n",
       " 104177,\n",
       " 104603,\n",
       " 104674,\n",
       " 104764,\n",
       " 104831,\n",
       " 104866,\n",
       " 104878,\n",
       " 104918,\n",
       " 104958,\n",
       " 105198,\n",
       " 105479,\n",
       " 105609,\n",
       " 105610,\n",
       " 105642,\n",
       " 105676,\n",
       " 105770,\n",
       " 105932,\n",
       " 106033,\n",
       " 106036,\n",
       " 106329,\n",
       " 106378,\n",
       " 106554,\n",
       " 106599,\n",
       " 106765,\n",
       " 106907,\n",
       " 106965,\n",
       " 107196,\n",
       " 107216,\n",
       " 107329,\n",
       " 107382,\n",
       " 107755,\n",
       " 107972,\n",
       " 108005,\n",
       " 108010,\n",
       " 108104,\n",
       " 108505,\n",
       " 108777,\n",
       " 108819,\n",
       " 108971,\n",
       " 109154,\n",
       " 109262,\n",
       " 109275,\n",
       " 109608,\n",
       " 109620,\n",
       " 109717,\n",
       " 109810,\n",
       " 109825,\n",
       " 110081,\n",
       " 110229,\n",
       " 110314,\n",
       " 110325,\n",
       " 110488,\n",
       " 110536,\n",
       " ...]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for (i, p) in posts_df[posts_df['tag'] == 'c#']['post_id'].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Howdy, how are ya?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How to create a web service in Django?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How to create a Numpy array?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How to print hello world in Java?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stackoverflow'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prepared_question = np.array([text_prepare(question)])\n",
    "tfidf_features = vectorizer.transform(prepared_question)\n",
    "intent_recognizer.predict(tfidf_features)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_classifier.predict(tfidf_features)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(q_emb, candidate_threads_emb, candidate_thread_ids):\n",
    "    \"\"\"\n",
    "        q_emb: embedding vector for a question\n",
    "        candidate_threads_emb: matrix of candidate thread embeddings which we want to rank\n",
    "        candidate_thread_ids: list of stackoverflow thread ids aligned with candidate_threads_emb\n",
    "        \n",
    "        result: a list of sorted tuples (initial position in the list, thread_id, cos_similiarity)\n",
    "    \"\"\"\n",
    "\n",
    "    canditate_similarities = cosine_similarity(q_emb.reshape(1, -1), candidate_threads_emb)[0]\n",
    "    sorted_candidates = sorted([(i, candidate_thread_ids[i], s) for (i, s) in enumerate(canditate_similarities)], key=lambda k: k[2], reverse=True)\n",
    "    return sorted_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"python\"\n",
    "thread_ids, thread_embeddings = unpickle_file(os.path.join(RESOURCE_PATH['THREAD_EMBEDDINGS_FOLDER'], os.path.normpath('%s.pkl' % tag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('create',\n",
       "  array([-0.0117805 ,  0.0226999 ,  0.0242219 ,  0.0397424 ,  0.00503275,\n",
       "          0.00431922,  0.0118978 ,  0.0438049 , -0.0220885 , -0.0105157 ,\n",
       "         -0.0436699 ,  0.0207152 , -0.00498137,  0.00757037, -0.0528204 ,\n",
       "         -0.00130005,  0.0543642 , -0.0172891 , -0.0204819 ,  0.0264255 ,\n",
       "          0.0246876 , -0.0404211 ,  0.0250035 , -0.0557527 , -0.010876  ,\n",
       "          0.0269171 ,  0.00794895, -0.00327785, -0.0263906 ,  0.0127513 ,\n",
       "         -0.0214427 , -0.0248284 ,  0.0227035 , -0.044855  , -0.0323937 ,\n",
       "          0.0325731 , -0.0730036 ,  0.0236489 ,  0.00977082, -0.0183327 ,\n",
       "          0.0149711 ,  0.037556  , -0.0237786 , -0.00751505,  0.0428431 ,\n",
       "          0.0536639 ,  0.0155935 , -0.0252742 ,  0.00580531,  0.0109279 ,\n",
       "          0.0260714 ,  0.00758684,  0.00270356, -0.00502032, -0.0469401 ,\n",
       "          0.00013093,  0.0832324 ,  0.00744033,  0.0123482 , -0.0226863 ,\n",
       "          0.0179812 ,  0.0292145 , -0.0426    ,  0.0136503 , -0.00322326,\n",
       "         -0.0297234 ,  0.0168456 , -0.0109219 ,  0.0198855 , -0.0273453 ,\n",
       "          0.00107282, -0.0642005 ,  0.0264447 ,  0.00614598,  0.0519531 ,\n",
       "          0.0186252 , -0.0109634 , -0.01155   , -0.0529657 , -0.0224376 ,\n",
       "         -0.013484  , -0.00342233, -0.0336726 , -0.0269293 , -0.0441488 ,\n",
       "          0.00873619,  0.0428091 , -0.0687949 ,  0.0261733 , -0.0186451 ,\n",
       "         -0.00556533,  0.0313282 ,  0.0139683 , -0.00137672,  0.0003125 ,\n",
       "          0.0402971 ,  0.00117551, -0.00333412,  0.0297936 ,  0.0113798 ],\n",
       "        dtype=float32)),\n",
       " ('web', array([-3.20833e-02,  3.02848e-02,  2.51830e-02, -2.30126e-02,\n",
       "          3.39471e-02, -2.17738e-02,  8.43784e-02,  2.04015e-02,\n",
       "          3.46806e-02, -2.00696e-02, -3.38314e-02,  3.72680e-02,\n",
       "          8.58370e-03,  3.27213e-02,  8.24417e-03,  3.54752e-03,\n",
       "          1.49023e-02,  4.16467e-03, -3.25250e-02,  6.89033e-02,\n",
       "         -3.66959e-02, -4.24529e-02, -3.06081e-03,  6.88665e-02,\n",
       "          4.84929e-02,  2.64044e-02,  6.72403e-02,  4.23535e-02,\n",
       "         -2.70853e-02, -2.29028e-02,  4.57686e-02, -4.23928e-02,\n",
       "          6.59437e-02, -2.37759e-02, -2.59528e-03, -3.41369e-02,\n",
       "         -6.61683e-02, -1.34526e-01, -1.64896e-02, -4.41553e-02,\n",
       "         -6.84431e-02, -5.61923e-02, -3.24193e-02, -1.53207e-02,\n",
       "         -1.93320e-02,  7.69614e-02, -4.29961e-02, -8.11845e-02,\n",
       "          3.51697e-02,  1.86740e-02,  7.06478e-02,  2.10566e-02,\n",
       "          2.09617e-02,  3.45819e-02,  2.12925e-02, -5.98134e-03,\n",
       "         -5.88838e-03,  9.62230e-04, -9.76841e-02, -5.40825e-02,\n",
       "         -4.14804e-03,  7.73013e-03,  2.23412e-03,  7.12095e-03,\n",
       "          3.73831e-02, -4.20530e-02,  4.53419e-03, -4.29605e-02,\n",
       "         -5.59128e-02, -5.48302e-02,  5.82130e-02,  3.05963e-02,\n",
       "         -4.26785e-02,  2.99277e-02, -4.30853e-02, -2.37424e-02,\n",
       "          3.50178e-02, -5.73188e-02, -3.06138e-02,  3.01543e-03,\n",
       "          1.67236e-02,  7.48117e-02,  1.89684e-02,  1.21875e-04,\n",
       "         -2.10063e-02,  3.55183e-02, -3.16066e-02,  7.57784e-03,\n",
       "         -4.92389e-02, -1.82254e-02, -3.56269e-02, -3.61745e-02,\n",
       "          2.42865e-02, -1.69975e-02, -3.60704e-02,  1.11887e-03,\n",
       "         -2.08797e-03,  2.36078e-02, -9.71955e-03, -6.92020e-02],\n",
       "        dtype=float32)),\n",
       " ('service',\n",
       "  array([ 0.0334327 , -0.0194068 , -0.0800457 ,  0.053886  , -0.0854443 ,\n",
       "          0.013275  , -0.0023877 ,  0.0171878 , -0.00137377,  0.0928956 ,\n",
       "          0.0241727 ,  0.0817507 ,  0.00188554, -0.0685967 ,  0.102095  ,\n",
       "          0.0109984 ,  0.0185552 , -0.0218889 ,  0.0279241 , -0.070249  ,\n",
       "         -0.0739939 ,  0.0089517 , -0.137177  , -0.0630122 , -0.0824418 ,\n",
       "          0.0425926 ,  0.0328354 ,  0.0896119 ,  0.0567113 , -0.0262838 ,\n",
       "          0.0439826 , -0.0375501 ,  0.0843747 ,  0.0190689 , -0.0470275 ,\n",
       "         -0.0240058 ,  0.0146897 ,  0.041195  ,  0.0327252 ,  0.00281043,\n",
       "         -0.00343786,  0.0530314 ,  0.0872722 , -0.00428063,  0.00055108,\n",
       "         -0.111105  , -0.0648605 ,  0.0113996 ,  0.0695726 , -0.0163172 ,\n",
       "          0.0163793 , -0.0166951 , -0.0336051 , -0.0280978 , -0.0356249 ,\n",
       "         -0.062936  ,  0.045323  , -0.0849502 , -0.0295014 ,  0.0177923 ,\n",
       "         -0.0618387 , -0.079276  ,  0.030914  , -0.0404307 , -0.0858764 ,\n",
       "          0.0203696 , -0.0874792 ,  0.00780588,  0.0747134 , -0.0082719 ,\n",
       "          0.0237153 , -0.0190495 ,  0.0411156 ,  0.016576  ,  0.0429831 ,\n",
       "         -0.0573646 , -0.0221444 , -0.0133509 , -0.0354574 , -0.00559073,\n",
       "          0.0546746 ,  0.0187564 , -0.0180315 , -0.0584697 ,  0.0238591 ,\n",
       "         -0.119475  , -0.039838  ,  0.00419367, -0.0268541 ,  0.054235  ,\n",
       "          0.0626304 ,  0.0676008 , -0.122635  ,  0.0540556 , -0.0816656 ,\n",
       "         -0.0135389 , -0.0228502 , -0.053485  ,  0.00416569,  0.0923158 ],\n",
       "        dtype=float32)),\n",
       " ('django',\n",
       "  array([-0.0720181 ,  0.153415  ,  0.0905004 , -0.0845244 ,  0.0275747 ,\n",
       "          0.118036  , -0.0135717 ,  0.0251334 , -0.0883782 ,  0.105599  ,\n",
       "          0.0362974 ,  0.0209106 ,  0.0520678 ,  0.104158  ,  0.0245094 ,\n",
       "          0.100166  , -0.0494838 ,  0.0738972 , -0.00783802,  0.154123  ,\n",
       "         -0.11878   , -0.00299319,  0.00665254, -0.0906515 , -0.0784464 ,\n",
       "          0.0795174 , -0.0237512 , -0.154462  , -0.0461307 , -0.0890465 ,\n",
       "         -0.0802547 ,  0.124715  ,  0.0418795 , -0.148465  ,  0.0164149 ,\n",
       "          0.0142943 ,  0.127304  ,  0.0179255 , -0.0488505 , -0.0494793 ,\n",
       "          0.122049  ,  0.0464269 ,  0.0398282 ,  0.0862151 , -0.130444  ,\n",
       "         -0.0791027 , -0.00697138,  0.00829364, -0.0649555 ,  0.0543801 ,\n",
       "         -0.117741  ,  0.086681  ,  0.0432413 , -0.0724668 ,  0.181387  ,\n",
       "          0.0650828 ,  0.0215075 ,  0.119307  ,  0.00508318,  0.0300402 ,\n",
       "          0.0223439 , -0.0504044 , -0.127935  , -0.164405  , -0.0305865 ,\n",
       "         -0.0508499 , -0.00637428, -0.0671182 , -0.0290692 ,  0.101961  ,\n",
       "          0.0239715 ,  0.0481697 ,  0.126947  ,  0.00213365, -0.136063  ,\n",
       "         -0.0330646 , -0.0524223 , -0.0539309 , -0.0860928 , -0.0883315 ,\n",
       "         -0.153053  ,  0.0105323 , -0.0297524 ,  0.0332408 , -0.094748  ,\n",
       "         -0.0238061 , -0.0762857 ,  0.0759328 ,  0.0501127 ,  0.0115166 ,\n",
       "          0.0077749 ,  0.070806  ,  0.121432  , -0.158144  ,  0.111109  ,\n",
       "          0.0338253 ,  0.0440707 ,  0.0645981 ,  0.0453022 ,  0.0224602 ],\n",
       "        dtype=float32))]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(w, starspace_embeddings[w]) for w in text_prepare(question).split(' ') if w in starspace_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vec = question_to_vec(text_prepare(question), starspace_embeddings, embeddings_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.0612299e-02,  4.6748225e-02,  1.4964900e-02, -3.4771506e-03,\n",
       "       -4.7224378e-03,  2.8464105e-02,  2.0079199e-02,  2.6631899e-02,\n",
       "       -1.9289967e-02,  4.1977324e-02, -4.2577991e-03,  4.0161125e-02,\n",
       "        1.4388918e-02,  1.8963244e-02,  2.0507043e-02,  2.8352968e-02,\n",
       "        9.5844753e-03,  9.7209662e-03, -8.2302047e-03,  4.4800699e-02,\n",
       "       -5.1195551e-02, -1.9228872e-02, -2.7145443e-02, -3.5137475e-02,\n",
       "       -3.0817825e-02,  4.3857872e-02,  2.1068363e-02, -6.4436086e-03,\n",
       "       -1.0723825e-02, -3.1370450e-02, -2.9865485e-03,  4.9859248e-03,\n",
       "        5.3725354e-02, -4.9506746e-02, -1.6400397e-02, -2.8188247e-03,\n",
       "        7.0545077e-04, -1.2939148e-02, -5.7110200e-03, -2.7289215e-02,\n",
       "        1.6284784e-02,  2.0205500e-02,  1.7725624e-02,  1.4774680e-02,\n",
       "       -2.6595455e-02, -1.4895603e-02, -2.4808621e-02, -2.1691367e-02,\n",
       "        1.1398025e-02,  1.6916201e-02, -1.1606254e-03,  2.4657335e-02,\n",
       "        8.3253654e-03, -1.7750755e-02,  3.0028626e-02, -9.2590041e-04,\n",
       "        3.6043629e-02,  1.0689840e-02, -2.7438531e-02, -7.2340751e-03,\n",
       "       -6.4154109e-03, -2.3183944e-02, -3.4346722e-02, -4.6016112e-02,\n",
       "       -2.0575766e-02, -2.5564175e-02, -1.8118421e-02, -2.8298680e-02,\n",
       "        2.4042260e-03,  2.8783996e-03,  2.6743155e-02, -1.1209995e-03,\n",
       "        3.7957199e-02,  1.3695832e-02, -2.1053024e-02, -2.3886601e-02,\n",
       "       -1.2628075e-02, -3.4037650e-02, -5.1282424e-02, -2.8336100e-02,\n",
       "       -2.3784701e-02,  2.5169516e-02, -1.5622025e-02, -1.3009082e-02,\n",
       "       -3.4010999e-02, -2.4756653e-02, -2.6230300e-02,  4.7273533e-03,\n",
       "        4.8249029e-05,  7.2202748e-03,  7.3032677e-03,  3.3390127e-02,\n",
       "        9.2629492e-03, -3.0615654e-02, -1.5786234e-03,  1.5425592e-02,\n",
       "        5.0770096e-03,  7.8466944e-03,  1.7385487e-02,  1.4238451e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10899, 759216, 0.79782104),\n",
       " (129531, 8320834, 0.79054666),\n",
       " (25035, 1547594, 0.79034626),\n",
       " (111787, 7042156, 0.79034626),\n",
       " (99143, 6176386, 0.78155243),\n",
       " (119934, 7625437, 0.77325296),\n",
       " (176696, 11826936, 0.7710525),\n",
       " (2341, 232318, 0.7599995),\n",
       " (85743, 5314369, 0.75826097),\n",
       " (78710, 4878775, 0.75708705),\n",
       " (148630, 9710374, 0.7518618),\n",
       " (20007, 1270146, 0.7504495),\n",
       " (61449, 3812361, 0.7454943),\n",
       " (47194, 2932907, 0.74521184),\n",
       " (58569, 3632860, 0.74521184),\n",
       " (83545, 5175488, 0.7440789),\n",
       " (206540, 14288377, 0.7379978),\n",
       " (56542, 3512229, 0.7353431),\n",
       " (43664, 2720335, 0.7337319),\n",
       " (50980, 3169996, 0.7337319),\n",
       " (26339, 1625170, 0.7327568),\n",
       " (57702, 3579238, 0.73252034),\n",
       " (17702, 1142994, 0.7315666),\n",
       " (19180, 1223374, 0.7315666),\n",
       " (55450, 3446497, 0.7306223),\n",
       " (125280, 8010212, 0.7306223),\n",
       " (177012, 11851533, 0.7306223),\n",
       " (181502, 12212213, 0.73014116),\n",
       " (181366, 12201776, 0.7300775),\n",
       " (966, 106329, 0.72969776),\n",
       " (2027, 208186, 0.72969776),\n",
       " (2906, 274315, 0.72969776),\n",
       " (3236, 295387, 0.72969776),\n",
       " (5395, 446474, 0.72969776),\n",
       " (5611, 459126, 0.72969776),\n",
       " (6935, 543612, 0.72969776),\n",
       " (7106, 555752, 0.72969776),\n",
       " (9851, 706181, 0.72969776),\n",
       " (10089, 717539, 0.72969776),\n",
       " (11564, 793561, 0.72969776),\n",
       " (12989, 869609, 0.72969776),\n",
       " (15504, 1014094, 0.72969776),\n",
       " (15768, 1029235, 0.72969776),\n",
       " (15950, 1040879, 0.72969776),\n",
       " (15962, 1041795, 0.72969776),\n",
       " (18850, 1205807, 0.72969776),\n",
       " (18914, 1208756, 0.72969776),\n",
       " (20558, 1299607, 0.72969776),\n",
       " (22133, 1385990, 0.72969776),\n",
       " (22840, 1426733, 0.72969776),\n",
       " (23247, 1447305, 0.72969776),\n",
       " (23992, 1489359, 0.72969776),\n",
       " (24740, 1531220, 0.72969776),\n",
       " (26169, 1615208, 0.72969776),\n",
       " (27744, 1709843, 0.72969776),\n",
       " (28655, 1771293, 0.72969776),\n",
       " (30581, 1897299, 0.72969776),\n",
       " (31936, 1989125, 0.72969776),\n",
       " (32003, 1994091, 0.72969776),\n",
       " (32135, 2004176, 0.72969776),\n",
       " (32594, 2030780, 0.72969776),\n",
       " (32948, 2051914, 0.72969776),\n",
       " (33185, 2064874, 0.72969776),\n",
       " (33254, 2068167, 0.72969776),\n",
       " (33789, 2103418, 0.72969776),\n",
       " (34535, 2153163, 0.72969776),\n",
       " (34649, 2160710, 0.72969776),\n",
       " (36151, 2259600, 0.72969776),\n",
       " (36538, 2283336, 0.72969776),\n",
       " (36965, 2310963, 0.72969776),\n",
       " (40474, 2526450, 0.72969776),\n",
       " (41162, 2567908, 0.72969776),\n",
       " (41634, 2598170, 0.72969776),\n",
       " (42570, 2652247, 0.72969776),\n",
       " (44618, 2777522, 0.72969776),\n",
       " (46022, 2866730, 0.72969776),\n",
       " (47682, 2962248, 0.72969776),\n",
       " (48639, 3021299, 0.72969776),\n",
       " (49604, 3084387, 0.72969776),\n",
       " (50970, 3169419, 0.72969776),\n",
       " (51402, 3196217, 0.72969776),\n",
       " (53941, 3352899, 0.72969776),\n",
       " (55165, 3429128, 0.72969776),\n",
       " (55880, 3469275, 0.72969776),\n",
       " (56225, 3492585, 0.72969776),\n",
       " (56530, 3511644, 0.72969776),\n",
       " (60397, 3750201, 0.72969776),\n",
       " (61386, 3808540, 0.72969776),\n",
       " (61453, 3812548, 0.72969776),\n",
       " (62073, 3849563, 0.72969776),\n",
       " (62099, 3850930, 0.72969776),\n",
       " (63254, 3920784, 0.72969776),\n",
       " (63689, 3946747, 0.72969776),\n",
       " (63960, 3964781, 0.72969776),\n",
       " (65208, 4036889, 0.72969776),\n",
       " (65630, 4063356, 0.72969776),\n",
       " (66263, 4099591, 0.72969776),\n",
       " (66311, 4102203, 0.72969776),\n",
       " (68415, 4234873, 0.72969776),\n",
       " (68579, 4245563, 0.72969776),\n",
       " (71304, 4409558, 0.72969776),\n",
       " (73524, 4551495, 0.72969776),\n",
       " (73882, 4575695, 0.72969776),\n",
       " (74679, 4623297, 0.72969776),\n",
       " (74941, 4640443, 0.72969776),\n",
       " (75722, 4687010, 0.72969776),\n",
       " (75953, 4702394, 0.72969776),\n",
       " (80368, 4984358, 0.72969776),\n",
       " (80607, 4999365, 0.72969776),\n",
       " (81797, 5073599, 0.72969776),\n",
       " (82984, 5143808, 0.72969776),\n",
       " (86913, 5385010, 0.72969776),\n",
       " (88378, 5482516, 0.72969776),\n",
       " (89755, 5571384, 0.72969776),\n",
       " (91552, 5684474, 0.72969776),\n",
       " (93896, 5842887, 0.72969776),\n",
       " (94322, 5869164, 0.72969776),\n",
       " (99385, 6191781, 0.72969776),\n",
       " (100663, 6273942, 0.72969776),\n",
       " (102295, 6381257, 0.72969776),\n",
       " (105215, 6574917, 0.72969776),\n",
       " (106225, 6647617, 0.72969776),\n",
       " (107257, 6719449, 0.72969776),\n",
       " (112030, 7061648, 0.72969776),\n",
       " (114026, 7198635, 0.72969776),\n",
       " (114139, 7206344, 0.72969776),\n",
       " (114499, 7232984, 0.72969776),\n",
       " (116695, 7388201, 0.72969776),\n",
       " (118283, 7499384, 0.72969776),\n",
       " (120158, 7642822, 0.72969776),\n",
       " (124853, 7979929, 0.72969776),\n",
       " (125784, 8048059, 0.72969776),\n",
       " (132129, 8510703, 0.72969776),\n",
       " (132577, 8544558, 0.72969776),\n",
       " (134273, 8665669, 0.72969776),\n",
       " (138402, 8961180, 0.72969776),\n",
       " (140427, 9102940, 0.72969776),\n",
       " (140971, 9146048, 0.72969776),\n",
       " (145458, 9479254, 0.72969776),\n",
       " (147164, 9603891, 0.72969776),\n",
       " (147864, 9654718, 0.72969776),\n",
       " (149343, 9767470, 0.72969776),\n",
       " (150912, 9885672, 0.72969776),\n",
       " (151551, 9931723, 0.72969776),\n",
       " (151552, 9931795, 0.72969776),\n",
       " (153104, 10046917, 0.72969776),\n",
       " (155063, 10192919, 0.72969776),\n",
       " (157262, 10354895, 0.72969776),\n",
       " (160544, 10608608, 0.72969776),\n",
       " (161371, 10674021, 0.72969776),\n",
       " (162026, 10721120, 0.72969776),\n",
       " (163629, 10836908, 0.72969776),\n",
       " (165183, 10953771, 0.72969776),\n",
       " (165881, 11009037, 0.72969776),\n",
       " (169726, 11291468, 0.72969776),\n",
       " (170406, 11342003, 0.72969776),\n",
       " (171900, 11457564, 0.72969776),\n",
       " (174417, 11650497, 0.72969776),\n",
       " (174990, 11690957, 0.72969776),\n",
       " (178614, 11983567, 0.72969776),\n",
       " (183940, 12406025, 0.72969776),\n",
       " (185360, 12518612, 0.72969776),\n",
       " (189373, 12843251, 0.72969776),\n",
       " (201154, 13811900, 0.72969776),\n",
       " (203155, 13982416, 0.72969776),\n",
       " (205039, 14155638, 0.72969776),\n",
       " (208342, 14447883, 0.72969776),\n",
       " (128404, 8238757, 0.7296691),\n",
       " (105975, 6627814, 0.72959536),\n",
       " (90343, 5607572, 0.7293547),\n",
       " (187745, 12715667, 0.7290306),\n",
       " (183866, 12401440, 0.7288054),\n",
       " (105910, 6623154, 0.7276327),\n",
       " (39120, 2442167, 0.72732747),\n",
       " (6975, 546590, 0.7264862),\n",
       " (45286, 2819366, 0.7264862),\n",
       " (87197, 5403071, 0.7264862),\n",
       " (98927, 6161113, 0.7264862),\n",
       " (120163, 7643549, 0.7264862),\n",
       " (123612, 7891433, 0.7264862),\n",
       " (24267, 1503305, 0.7263813),\n",
       " (37611, 2350360, 0.7263813),\n",
       " (39692, 2476434, 0.7263813),\n",
       " (90582, 5623037, 0.7263813),\n",
       " (102059, 6366610, 0.7263813),\n",
       " (116778, 7394066, 0.7263813),\n",
       " (122673, 7823940, 0.7263813),\n",
       " (177209, 11868329, 0.7263813),\n",
       " (192955, 13126053, 0.7263813),\n",
       " (200083, 13718227, 0.7263813),\n",
       " (35961, 2247218, 0.7261424),\n",
       " (63624, 3942567, 0.7248961),\n",
       " (26658, 1644609, 0.7244626),\n",
       " (161455, 10681976, 0.72137874),\n",
       " (41763, 2605896, 0.7213616),\n",
       " (91279, 5667358, 0.7208936),\n",
       " (12110, 823313, 0.7197001),\n",
       " (35066, 2186686, 0.719383),\n",
       " (63219, 3919312, 0.719383),\n",
       " (66977, 4145040, 0.719383),\n",
       " (71765, 4439609, 0.719383),\n",
       " (5781, 469772, 0.7191552),\n",
       " (4383, 376910, 0.7185104),\n",
       " (66875, 4138875, 0.7167531),\n",
       " (156274, 10283206, 0.7153318),\n",
       " (190240, 12913890, 0.7153318),\n",
       " (196011, 13374327, 0.7152891),\n",
       " (20849, 1314722, 0.71484447),\n",
       " (24294, 1504667, 0.71483463),\n",
       " (72643, 4494030, 0.7134461),\n",
       " (131730, 8481643, 0.71307886),\n",
       " (52298, 3251308, 0.712695),\n",
       " (169785, 11295515, 0.71199554),\n",
       " (91718, 5695275, 0.7109446),\n",
       " (161620, 10694121, 0.71067333),\n",
       " (156234, 10280328, 0.7104014),\n",
       " (122247, 7795064, 0.7102643),\n",
       " (95831, 5964205, 0.70932174),\n",
       " (56357, 3501006, 0.70892644),\n",
       " (27954, 1724700, 0.7087562),\n",
       " (71325, 4410895, 0.7087562),\n",
       " (120812, 7687561, 0.7087562),\n",
       " (132425, 8531748, 0.7087562),\n",
       " (109990, 6912082, 0.70800054),\n",
       " (40493, 2527499, 0.7078445),\n",
       " (32036, 1996767, 0.70734733),\n",
       " (33876, 2109126, 0.7072935),\n",
       " (79204, 4909603, 0.7072935),\n",
       " (153862, 10105396, 0.7072935),\n",
       " (16526, 1073706, 0.70675766),\n",
       " (88884, 5516264, 0.70675766),\n",
       " (2747, 262691, 0.70625556),\n",
       " (60756, 3769961, 0.70619833),\n",
       " (67438, 4174215, 0.70619833),\n",
       " (140203, 9086967, 0.70619833),\n",
       " (157087, 10342266, 0.70619833),\n",
       " (9916, 709248, 0.704337),\n",
       " (19636, 1249091, 0.704337),\n",
       " (51656, 3211277, 0.704337),\n",
       " (67637, 4187008, 0.70403516),\n",
       " (29195, 1804302, 0.70388347),\n",
       " (31916, 1987417, 0.70388347),\n",
       " (68327, 4228276, 0.70354587),\n",
       " (192993, 13128493, 0.70214605),\n",
       " (114477, 7231637, 0.7012993),\n",
       " (187675, 12710355, 0.70125437),\n",
       " (151918, 9957908, 0.7011186),\n",
       " (175079, 11698200, 0.7009281),\n",
       " (60852, 3776458, 0.7001175),\n",
       " (89585, 5561795, 0.69979835),\n",
       " (97320, 6059020, 0.69979835),\n",
       " (120280, 7650592, 0.69979835),\n",
       " (148218, 9682224, 0.69979835),\n",
       " (157740, 10392458, 0.69979835),\n",
       " (59320, 3682521, 0.6995087),\n",
       " (178225, 11953115, 0.6995087),\n",
       " (676, 73775, 0.6993363),\n",
       " (29505, 1825574, 0.69914025),\n",
       " (180529, 12134379, 0.6991312),\n",
       " (195027, 13290421, 0.6982061),\n",
       " (18564, 1189420, 0.6981472),\n",
       " (44284, 2756484, 0.6978655),\n",
       " (21470, 1349058, 0.6972501),\n",
       " (171783, 11449815, 0.69705045),\n",
       " (4896, 416306, 0.69698185),\n",
       " (48420, 3007350, 0.69673365),\n",
       " (200344, 13739462, 0.69625676),\n",
       " (52408, 3257021, 0.69624364),\n",
       " (13939, 925571, 0.6957822),\n",
       " (34732, 2165232, 0.69543827),\n",
       " (185960, 12570649, 0.69502807),\n",
       " (19615, 1247398, 0.6947521),\n",
       " (82980, 5143338, 0.694042),\n",
       " (84586, 5240110, 0.69351757),\n",
       " (6495, 517935, 0.69340676),\n",
       " (165860, 11007027, 0.69340676),\n",
       " (185425, 12524737, 0.69340676),\n",
       " (57947, 3596604, 0.69328606),\n",
       " (7233, 564358, 0.69296443),\n",
       " (15653, 1023489, 0.69264454),\n",
       " (6693, 530539, 0.6925844),\n",
       " (102753, 6412953, 0.691944),\n",
       " (39623, 2472003, 0.6918085),\n",
       " (76746, 4751002, 0.6918085),\n",
       " (187220, 12674195, 0.6917855),\n",
       " (7311, 568164, 0.69145477),\n",
       " (92871, 5770321, 0.69145477),\n",
       " (134793, 8705440, 0.69140077),\n",
       " (88451, 5487454, 0.6912663),\n",
       " (98816, 6153338, 0.6906069),\n",
       " (36754, 2296988, 0.69057703),\n",
       " (120155, 7642205, 0.69057703),\n",
       " (197853, 13528210, 0.69057703),\n",
       " (197743, 13519281, 0.69045234),\n",
       " (16478, 1070162, 0.6902714),\n",
       " (69023, 4269983, 0.6902714),\n",
       " (10861, 756984, 0.6901872),\n",
       " (170551, 11352602, 0.6895846),\n",
       " (17914, 1155694, 0.6893828),\n",
       " (2347, 232545, 0.688297),\n",
       " (37373, 2334486, 0.688297),\n",
       " (116565, 7379394, 0.688297),\n",
       " (71680, 4433676, 0.68825924),\n",
       " (206249, 14264913, 0.6878289),\n",
       " (19905, 1264436, 0.68766963),\n",
       " (34639, 2160017, 0.68766963),\n",
       " (35162, 2193012, 0.68766963),\n",
       " (46200, 2876752, 0.68766963),\n",
       " (50291, 3128194, 0.68766963),\n",
       " (52299, 3251367, 0.68766963),\n",
       " (66768, 4132137, 0.68766963),\n",
       " (67528, 4181018, 0.68766963),\n",
       " (71471, 4420185, 0.68766963),\n",
       " (131518, 8466475, 0.68766963),\n",
       " (3248, 296251, 0.686509),\n",
       " (15423, 1009875, 0.68649596),\n",
       " (50421, 3136147, 0.68649596),\n",
       " (91873, 5705050, 0.6863502),\n",
       " (113499, 7164419, 0.6863502),\n",
       " (204197, 14077168, 0.6859247),\n",
       " (68706, 4253162, 0.6856577),\n",
       " (160140, 10579446, 0.6856257),\n",
       " (110328, 6937120, 0.6852677),\n",
       " (38351, 2395453, 0.68524224),\n",
       " (77263, 4783857, 0.68524224),\n",
       " (37914, 2369256, 0.6846988),\n",
       " (60190, 3737848, 0.68394035),\n",
       " (51032, 3174796, 0.6834058),\n",
       " (71625, 4429979, 0.6833463),\n",
       " (199028, 13628269, 0.68264633),\n",
       " (8459, 634268, 0.68259037),\n",
       " (51797, 3219920, 0.6821172),\n",
       " (2687, 258481, 0.6819043),\n",
       " (26106, 1611936, 0.681524),\n",
       " (192050, 13053737, 0.68096364),\n",
       " (51596, 3206831, 0.6807604),\n",
       " (25910, 1601292, 0.6806903),\n",
       " (92846, 5768862, 0.6806789),\n",
       " (59917, 3721199, 0.6805558),\n",
       " (168123, 11168003, 0.68015325),\n",
       " (69623, 4306759, 0.67995965),\n",
       " (49546, 3080854, 0.6797468),\n",
       " (84981, 5265367, 0.6797213),\n",
       " (33600, 2090036, 0.6797116),\n",
       " (71562, 4426864, 0.6796595),\n",
       " (73767, 4567569, 0.6796168),\n",
       " (44539, 2772291, 0.6793184),\n",
       " (90692, 5629071, 0.678973),\n",
       " (119367, 7580710, 0.67897266),\n",
       " (105752, 6611758, 0.67878956),\n",
       " (181233, 12192067, 0.6786591),\n",
       " (120876, 7691230, 0.6786319),\n",
       " (130362, 8380641, 0.6786076),\n",
       " (189033, 12816327, 0.6784505),\n",
       " (29739, 1839558, 0.6780715),\n",
       " (59363, 3684959, 0.678054),\n",
       " (73618, 4557419, 0.678054),\n",
       " (83060, 5148796, 0.678054),\n",
       " (110900, 6981002, 0.678054),\n",
       " (73628, 4558141, 0.6775943),\n",
       " (91556, 5684881, 0.6774988),\n",
       " (205629, 14210175, 0.6774924),\n",
       " (178601, 11982200, 0.67727447),\n",
       " (18601, 1191919, 0.6772164),\n",
       " (203586, 14024024, 0.6766819),\n",
       " (9672, 695844, 0.67667425),\n",
       " (167302, 11106217, 0.6765654),\n",
       " (86947, 5387824, 0.67617524),\n",
       " (64961, 4022399, 0.676088),\n",
       " (143831, 9357766, 0.6759481),\n",
       " (142904, 9288071, 0.67565835),\n",
       " (100271, 6250787, 0.67543274),\n",
       " (148007, 9665434, 0.67540324),\n",
       " (77745, 4814878, 0.67519474),\n",
       " (13756, 916608, 0.6748442),\n",
       " (10233, 724912, 0.6748011),\n",
       " (11390, 785462, 0.6748011),\n",
       " (57956, 3597276, 0.6748011),\n",
       " (74929, 4639482, 0.6747676),\n",
       " (20376, 1289950, 0.6747056),\n",
       " (11760, 803059, 0.6746172),\n",
       " (29206, 1805019, 0.67457986),\n",
       " (21056, 1326574, 0.674345),\n",
       " (116664, 7386701, 0.674345),\n",
       " (24436, 1512562, 0.6742917),\n",
       " (73975, 4581749, 0.6741359),\n",
       " (190444, 12930868, 0.67403865),\n",
       " (19293, 1228552, 0.6738899),\n",
       " (30314, 1879795, 0.6738899),\n",
       " (34480, 2150295, 0.6738899),\n",
       " (46194, 2876255, 0.6738899),\n",
       " (47862, 2972889, 0.6738899),\n",
       " (52975, 3291895, 0.6738899),\n",
       " (119672, 7603409, 0.6738899),\n",
       " (161486, 10684358, 0.6738899),\n",
       " (196955, 13451791, 0.6738899),\n",
       " (12651, 852171, 0.67373693),\n",
       " (18642, 1194058, 0.67373693),\n",
       " (41598, 2595992, 0.67373693),\n",
       " (43791, 2727480, 0.67373693),\n",
       " (46063, 2868704, 0.67373693),\n",
       " (128084, 8215236, 0.67373693),\n",
       " (165230, 10957646, 0.67373693),\n",
       " (173796, 11607991, 0.67373693),\n",
       " (206926, 14324257, 0.67373693),\n",
       " (95429, 5942051, 0.67366105),\n",
       " (131084, 8433259, 0.67339414),\n",
       " (161427, 10679515, 0.6732502),\n",
       " (61987, 3843719, 0.6732399),\n",
       " (110823, 6974179, 0.6731774),\n",
       " (166186, 11029698, 0.67311066),\n",
       " (15864, 1035632, 0.6730077),\n",
       " (28830, 1783310, 0.6729358),\n",
       " (24349, 1508251, 0.67280966),\n",
       " (19332, 1231672, 0.67272246),\n",
       " (199182, 13641671, 0.6727153),\n",
       " (4907, 416968, 0.6727079),\n",
       " (11494, 790093, 0.6727079),\n",
       " (34814, 2170614, 0.6727079),\n",
       " (53478, 3324136, 0.6727079),\n",
       " (68852, 4260836, 0.6727079),\n",
       " (71676, 4433561, 0.6727079),\n",
       " (104402, 6521285, 0.6727079),\n",
       " (120225, 7647437, 0.6727079),\n",
       " (125710, 8042398, 0.6727079),\n",
       " (170404, 11341968, 0.6727079),\n",
       " (7245, 564935, 0.67264384),\n",
       " (19620, 1247858, 0.67264384),\n",
       " (88961, 5521702, 0.6725192),\n",
       " (47655, 2960677, 0.672446),\n",
       " (153899, 10107792, 0.6723342),\n",
       " (4579, 392832, 0.6722765),\n",
       " (154012, 10116036, 0.67210793),\n",
       " (41259, 2575438, 0.67207515),\n",
       " (73807, 4569961, 0.6720246),\n",
       " (204039, 14063465, 0.67178696),\n",
       " (5960, 480538, 0.6716126),\n",
       " (170798, 11372808, 0.67147166),\n",
       " (68622, 4247893, 0.6714016),\n",
       " (133682, 8624037, 0.67133135),\n",
       " (10509, 738373, 0.67128617),\n",
       " (125770, 8047177, 0.6705819),\n",
       " (147008, 9594293, 0.6705196),\n",
       " (161411, 10677669, 0.6704931),\n",
       " (151375, 9919210, 0.6704812),\n",
       " (61990, 3843930, 0.6703553),\n",
       " (28133, 1738511, 0.67022145),\n",
       " (53894, 3349711, 0.67014414),\n",
       " (18149, 1167164, 0.66999876),\n",
       " (27775, 1712064, 0.66999876),\n",
       " (33413, 2077265, 0.66999876),\n",
       " (35986, 2248327, 0.66999876),\n",
       " (36564, 2285162, 0.66999876),\n",
       " (40988, 2556447, 0.66999876),\n",
       " (93988, 5849571, 0.66999876),\n",
       " (109605, 6884143, 0.66999876),\n",
       " (173659, 11596343, 0.66999876),\n",
       " (180581, 12138731, 0.66999876),\n",
       " (181387, 12202582, 0.66999876),\n",
       " (192420, 13082976, 0.66999876),\n",
       " (192435, 13083893, 0.6699961),\n",
       " (140266, 9091618, 0.66993535),\n",
       " (10908, 759484, 0.6699039),\n",
       " (68876, 4262147, 0.6699039),\n",
       " (130602, 8397592, 0.6699039),\n",
       " (46891, 2915914, 0.6698568),\n",
       " (74119, 4590324, 0.6696336),\n",
       " (116871, 7400511, 0.6695233),\n",
       " (111230, 7002133, 0.6693349),\n",
       " (60768, 3770676, 0.6691177),\n",
       " (183498, 12373041, 0.6690319),\n",
       " (67540, 4181796, 0.66894174),\n",
       " (119363, 7580399, 0.6689211),\n",
       " (169429, 11266382, 0.6687945),\n",
       " (60953, 3781931, 0.6684856),\n",
       " (72308, 4472232, 0.6684856),\n",
       " (33708, 2097539, 0.6684697),\n",
       " (166454, 11048959, 0.66840386),\n",
       " (207284, 14355528, 0.6684015),\n",
       " (48284, 2998905, 0.66785383),\n",
       " (88331, 5478425, 0.6677644),\n",
       " (61443, 3812200, 0.66756594),\n",
       " (27686, 1706112, 0.6673832),\n",
       " (112307, 7081022, 0.66698545),\n",
       " (30089, 1864285, 0.6669589),\n",
       " (55216, 3432456, 0.6669412),\n",
       " (10279, 727074, 0.66692376),\n",
       " (161077, 10649843, 0.66687405),\n",
       " (183452, 12369853, 0.66687405),\n",
       " (7292, 567228, 0.6668482),\n",
       " (18526, 1187219, 0.6668482),\n",
       " (26655, 1644560, 0.6668482),\n",
       " (36707, 2293778, 0.6668482),\n",
       " (41451, 2587326, 0.6668482),\n",
       " (44633, 2778848, 0.6668482),\n",
       " (73630, 4558415, 0.6668482),\n",
       " (117784, 7465543, 0.6668482),\n",
       " (120500, 7665838, 0.6668482),\n",
       " (135166, 8733250, 0.6668482),\n",
       " (153037, 10041950, 0.6668482),\n",
       " (153106, 10047179, 0.6668482),\n",
       " (162291, 10739641, 0.6668482),\n",
       " (165156, 10951145, 0.6668482),\n",
       " (174650, 11667055, 0.6668482),\n",
       " (179866, 12079565, 0.6668482),\n",
       " (185374, 12519753, 0.6668482),\n",
       " (189143, 12823850, 0.6668482),\n",
       " (190148, 12906009, 0.6668482),\n",
       " (193289, 13151925, 0.6668482),\n",
       " (193480, 13165859, 0.6668482),\n",
       " (205207, 14171235, 0.6668482),\n",
       " (205911, 14233051, 0.6668482),\n",
       " (170821, 11374585, 0.66668475),\n",
       " (128056, 8213352, 0.66626644),\n",
       " (5056, 425655, 0.66618407),\n",
       " (72739, 4499618, 0.66615486),\n",
       " (77606, 4805656, 0.66615486),\n",
       " (182361, 12283126, 0.66615486),\n",
       " (67097, 4151952, 0.66592467),\n",
       " (159707, 10543782, 0.6656641),\n",
       " (120077, 7636753, 0.66561496),\n",
       " (45560, 2835637, 0.66552985),\n",
       " (68311, 4226522, 0.6654491),\n",
       " (9204, 672539, 0.6654409),\n",
       " (108351, 6795865, 0.66533613),\n",
       " (38814, 2422464, 0.6653178),\n",
       " (14959, 981632, 0.6648429),\n",
       " (46683, 2904231, 0.6647445),\n",
       " (6365, 508293, 0.6644267),\n",
       " (160771, 10625789, 0.6640273),\n",
       " (10257, 726075, 0.6639918),\n",
       " (32803, 2044042, 0.6639918),\n",
       " (50076, 3112958, 0.6639918),\n",
       " (84519, 5236131, 0.6639918),\n",
       " (103767, 6477556, 0.6639918),\n",
       " (190096, 12901811, 0.6639918),\n",
       " (71272, 4407936, 0.6638753),\n",
       " (16688, 1085764, 0.66378915),\n",
       " (51326, 3191969, 0.6635871),\n",
       " (56634, 3517741, 0.6635871),\n",
       " (56727, 3522936, 0.66351444),\n",
       " (133975, 8644503, 0.6634853),\n",
       " (12567, 848399, 0.66339433),\n",
       " (99492, 6199103, 0.663372),\n",
       " (155345, 10213213, 0.66319233),\n",
       " (60345, 3747582, 0.6630379),\n",
       " (51189, 3184675, 0.6629901),\n",
       " (26622, 1643368, 0.66263866),\n",
       " (23774, 1475865, 0.66239715),\n",
       " (91026, 5650405, 0.66229725),\n",
       " (37189, 2324296, 0.66228354),\n",
       " (172034, 11467080, 0.662156),\n",
       " (5872, 474564, 0.66208947),\n",
       " (11507, 790592, 0.66208947),\n",
       " (74384, 4606948, 0.66208947),\n",
       " (101096, 6303425, 0.66208947),\n",
       " (160274, 10588601, 0.66208947),\n",
       " (184953, 12484996, 0.66208947),\n",
       " (205760, 14220173, 0.66208947),\n",
       " (91383, 5673185, 0.6620404),\n",
       " (91244, 5665333, 0.6618755),\n",
       " (29522, 1826593, 0.66158926),\n",
       " (65017, 4025428, 0.6613997),\n",
       " (59609, 3702658, 0.66123223),\n",
       " (72793, 4502706, 0.6612297),\n",
       " (24926, 1541381, 0.66114205),\n",
       " (28552, 1765510, 0.66114205),\n",
       " (57483, 3565608, 0.66114205),\n",
       " (64514, 3994389, 0.66114205),\n",
       " (80072, 4963345, 0.66114205),\n",
       " (90724, 5631319, 0.66114205),\n",
       " (125618, 8036719, 0.66114205),\n",
       " (166392, 11044661, 0.66114205),\n",
       " (175476, 11730659, 0.66114205),\n",
       " (193264, 13150171, 0.66114205),\n",
       " (200249, 13730803, 0.66114205),\n",
       " (6158, 495026, 0.6611252),\n",
       " (95460, 5944271, 0.66101515),\n",
       " (65726, 4069009, 0.6609135),\n",
       " (162368, 10744849, 0.6608341),\n",
       " (39512, 2465226, 0.6606617),\n",
       " (148006, 9665351, 0.66063917),\n",
       " (160345, 10594476, 0.6601753),\n",
       " (189458, 12849341, 0.66013765),\n",
       " (69383, 4290297, 0.659955),\n",
       " (122330, 7801906, 0.6598285),\n",
       " (156237, 10280536, 0.6597072),\n",
       " (134028, 8648065, 0.6596837),\n",
       " (4812, 411515, 0.65963125),\n",
       " (26112, 1612413, 0.6595398),\n",
       " (50577, 3145511, 0.6594814),\n",
       " (60250, 3741708, 0.65936506),\n",
       " (68230, 4221850, 0.65936506),\n",
       " (73588, 4555556, 0.65936506),\n",
       " (15743, 1028053, 0.65926874),\n",
       " (67343, 4166493, 0.6592358),\n",
       " (68865, 4261209, 0.65892404),\n",
       " (82686, 5123886, 0.6589029),\n",
       " (200521, 13753804, 0.658901),\n",
       " (39851, 2488037, 0.6588577),\n",
       " (149895, 9807952, 0.6588577),\n",
       " (42935, 2676243, 0.6588545),\n",
       " (39970, 2494451, 0.65883815),\n",
       " (75477, 4672752, 0.65883815),\n",
       " (20250, 1283681, 0.6587939),\n",
       " (3578, 318756, 0.658777),\n",
       " (11780, 804155, 0.658777),\n",
       " (28534, 1763926, 0.658777),\n",
       " (30735, 1906525, 0.658777),\n",
       " (43158, 2689490, 0.658777),\n",
       " (53636, 3334128, 0.658777),\n",
       " (59369, 3685239, 0.658777),\n",
       " (87333, 5411206, 0.658777),\n",
       " (87420, 5416270, 0.658777),\n",
       " (87649, 5431136, 0.658777),\n",
       " (97852, 6093826, 0.658777),\n",
       " (110720, 6964564, 0.658777),\n",
       " (149973, 9814603, 0.658777),\n",
       " (174074, 11627792, 0.658777),\n",
       " (202061, 13887656, 0.658777),\n",
       " (44039, 2741607, 0.6586839),\n",
       " (10095, 717657, 0.6586192),\n",
       " (67671, 4189563, 0.6585255),\n",
       " (63299, 3923276, 0.65847194),\n",
       " (67497, 4178195, 0.6583393),\n",
       " (174050, 11626600, 0.6581458),\n",
       " (64101, 3971523, 0.6580258),\n",
       " (4947, 419044, 0.65780944),\n",
       " (51880, 3225900, 0.6577736),\n",
       " (68019, 4210047, 0.65774155),\n",
       " (171171, 11402424, 0.65770674),\n",
       " (162655, 10765116, 0.6576431),\n",
       " (30972, 1921612, 0.6575431),\n",
       " (13267, 887437, 0.65748405),\n",
       " (6077, 489171, 0.65735877),\n",
       " (53011, 3293429, 0.65735877),\n",
       " (249, 26877, 0.65732193),\n",
       " (10572, 742428, 0.65732193),\n",
       " (15280, 1001694, 0.65732193),\n",
       " (16066, 1047063, 0.65732193),\n",
       " (64045, 3968179, 0.65732193),\n",
       " (152107, 9973758, 0.6573127),\n",
       " (80992, 5023003, 0.65710455),\n",
       " (49232, 3060108, 0.6567433),\n",
       " (74149, 4591964, 0.65668947),\n",
       " (149829, 9803839, 0.65668947),\n",
       " (117707, 7459903, 0.6563771),\n",
       " (92932, 5776228, 0.6563637),\n",
       " (105981, 6628177, 0.6563151),\n",
       " (156407, 10292166, 0.6560526),\n",
       " (92025, 5714800, 0.6560099),\n",
       " (192802, 13114657, 0.6559308),\n",
       " (34741, 2165530, 0.65586305),\n",
       " (37883, 2366752, 0.6558403),\n",
       " (26751, 1650395, 0.6558401),\n",
       " (107399, 6730132, 0.6556839),\n",
       " (19233, 1225968, 0.6556549),\n",
       " (93940, 5846828, 0.6553925),\n",
       " (66667, 4125750, 0.6552193),\n",
       " (140818, 9133399, 0.6549592),\n",
       " (61780, 3831521, 0.6549567),\n",
       " (87121, 5398702, 0.6549518),\n",
       " (26444, 1631734, 0.6547855),\n",
       " (46381, 2885853, 0.6547855),\n",
       " (66264, 4099621, 0.6547855),\n",
       " (45608, 2839946, 0.6546432),\n",
       " (151749, 9945914, 0.6543197),\n",
       " (204561, 14112559, 0.6542903),\n",
       " (98322, 6122354, 0.65418464),\n",
       " (95113, 5919652, 0.6541575),\n",
       " (149396, 9770505, 0.6541397),\n",
       " (159017, 10494154, 0.6541397),\n",
       " (98230, 6115961, 0.654088),\n",
       " (53400, 3318222, 0.6539761),\n",
       " (85694, 5312229, 0.65388453),\n",
       " (126809, 8122459, 0.6538652),\n",
       " (10960, 762945, 0.6537788),\n",
       " (191507, 13012585, 0.6537653),\n",
       " (89142, 5533867, 0.65361416),\n",
       " (156643, 10311104, 0.65361416),\n",
       " (186438, 12608414, 0.65361416),\n",
       " (40330, 2517550, 0.65361214),\n",
       " (165568, 10984632, 0.653581),\n",
       " (84177, 5216554, 0.65352976),\n",
       " (135193, 8734700, 0.65328074),\n",
       " (33736, 2099819, 0.6531985),\n",
       " (49617, 3084759, 0.6531985),\n",
       " (54952, 3416211, 0.6531985),\n",
       " (61968, 3842357, 0.6531985),\n",
       " (65775, 4071988, 0.6531985),\n",
       " (83310, 5162243, 0.6531985),\n",
       " (90598, 5624122, 0.6531985),\n",
       " (98467, 6130724, 0.6531985),\n",
       " (105025, 6561990, 0.6531985),\n",
       " (119888, 7620957, 0.6531985),\n",
       " (162573, 10758891, 0.6531985),\n",
       " (186642, 12624193, 0.6531985),\n",
       " (192849, 13118178, 0.6531985),\n",
       " (206691, 14301821, 0.6531985),\n",
       " (157162, 10348398, 0.65293247),\n",
       " (79335, 4918093, 0.65284264),\n",
       " (189291, 12836905, 0.6528053),\n",
       " (114818, 7255090, 0.65267766),\n",
       " (12898, 863747, 0.65261996),\n",
       " (113348, 7153831, 0.65261304),\n",
       " (159235, 10508962, 0.6525386),\n",
       " (7998, 608732, 0.65251786),\n",
       " (117732, 7462335, 0.65251786),\n",
       " (173569, 11588796, 0.65251786),\n",
       " (35107, 2188501, 0.6525116),\n",
       " (200274, 13732950, 0.6524519),\n",
       " (99017, 6167213, 0.6524224),\n",
       " (130426, 8384701, 0.6524224),\n",
       " (132757, 8559289, 0.65240514),\n",
       " (22041, 1379720, 0.65226614),\n",
       " (152586, 10009661, 0.6522058),\n",
       " (171592, 11434382, 0.6522058),\n",
       " (110805, 6972449, 0.65216285),\n",
       " (158587, 10458862, 0.65216285),\n",
       " (32824, 2045353, 0.6521418),\n",
       " (14011, 929458, 0.6521349),\n",
       " (8811, 652432, 0.6521336),\n",
       " (105656, 6605694, 0.6521183),\n",
       " (33419, 2077692, 0.65209377),\n",
       " (69035, 4270541, 0.6518723),\n",
       " (158964, 10489225, 0.65173936),\n",
       " (61977, 3842932, 0.65170753),\n",
       " (109262, 6857803, 0.6516826),\n",
       " (139532, 9036966, 0.65167165),\n",
       " (183117, 12345292, 0.65161353),\n",
       " (51271, 3188350, 0.6514224),\n",
       " (165450, 10976206, 0.65133286),\n",
       " (71633, 4430302, 0.65108293),\n",
       " (90244, 5600974, 0.6508275),\n",
       " (112398, 7088432, 0.65075827),\n",
       " (42259, 2635868, 0.6506497),\n",
       " (57884, 3591952, 0.65015125),\n",
       " (61027, 3786361, 0.65012026),\n",
       " (136569, 8833263, 0.65004134),\n",
       " (39201, 2447847, 0.6500405),\n",
       " (10286, 727280, 0.64985013),\n",
       " (97886, 6095613, 0.64985013),\n",
       " (59619, 3703052, 0.6496886),\n",
       " (182558, 12299827, 0.64963216),\n",
       " (161216, 10659308, 0.6495982),\n",
       " (105827, 6616633, 0.64959157),\n",
       " (107341, 6724840, 0.64951754),\n",
       " (104698, 6540154, 0.6494965),\n",
       " (16417, 1067274, 0.64944893),\n",
       " (128018, 8210296, 0.64921665),\n",
       " (61863, 3837216, 0.64920104),\n",
       " (65150, 4033489, 0.6491399),\n",
       " (65963, 4083977, 0.6491399),\n",
       " (87076, 5396130, 0.6491399),\n",
       " (104590, 6532923, 0.6491399),\n",
       " (181023, 12173803, 0.6491399),\n",
       " (86253, 5345200, 0.649122),\n",
       " (19863, 1262219, 0.6489808),\n",
       " (21955, 1375026, 0.6488745),\n",
       " (125170, 8002148, 0.64887285),\n",
       " (10347, 730335, 0.64880526),\n",
       " (147677, 9639569, 0.64880526),\n",
       " (29655, 1833432, 0.64860547),\n",
       " (83495, 5172542, 0.6485561),\n",
       " (40627, 2536071, 0.64855057),\n",
       " (127416, 8166896, 0.64853877),\n",
       " (65124, 4031943, 0.648486),\n",
       " (49858, 3099472, 0.6483762),\n",
       " (27595, 1700692, 0.6483668),\n",
       " (10968, 763257, 0.64827454),\n",
       " (188283, 12756114, 0.64827454),\n",
       " (187308, 12680039, 0.6482394),\n",
       " (98848, 6155481, 0.648185),\n",
       " (14356, 948039, 0.6480341),\n",
       " (143219, 9312411, 0.648023),\n",
       " (38740, 2417734, 0.6479981),\n",
       " (57354, 3557447, 0.6479981),\n",
       " (51030, 3174671, 0.6479746),\n",
       " (28844, 1784446, 0.64795184),\n",
       " (37752, 2358575, 0.6479312),\n",
       " (57287, 3553846, 0.6479312),\n",
       " (58983, 3661536, 0.6479312),\n",
       " (65212, 4037250, 0.6479301),\n",
       " (108327, 6794335, 0.64781713),\n",
       " (189180, 12826354, 0.6477244),\n",
       " (61192, 3798142, 0.6476531),\n",
       " (17451, 1129343, 0.64761806),\n",
       " (82498, 5113705, 0.64761806),\n",
       " (104454, 6524020, 0.64760363),\n",
       " (75085, 4648798, 0.6471536),\n",
       " (34063, 2121725, 0.64715284),\n",
       " (62098, 3850926, 0.6471063),\n",
       " (179530, 12054273, 0.64708865),\n",
       " (16664, 1083691, 0.6470015),\n",
       " (135099, 8729213, 0.64687145),\n",
       " (207235, 14351267, 0.6468679),\n",
       " (162266, 10737892, 0.64684117),\n",
       " (20735, 1308616, 0.6468252),\n",
       " (18502, 1186080, 0.64677763),\n",
       " (44905, 2795607, 0.646749),\n",
       " (89783, 5573174, 0.6466978),\n",
       " (33433, 2078923, 0.6466956),\n",
       " (158981, 10490092, 0.6466956),\n",
       " (23155, 1442332, 0.646656),\n",
       " (33330, 2072856, 0.64646363),\n",
       " (33714, 2097888, 0.64646363),\n",
       " (46480, 2892551, 0.64646363),\n",
       " (103171, 6437489, 0.64646363),\n",
       " (119265, 7573165, 0.64646363),\n",
       " (169930, 11306995, 0.64646363),\n",
       " (187869, 12725927, 0.64643925),\n",
       " (18212, 1169943, 0.6463625),\n",
       " (64636, 4002591, 0.64609826),\n",
       " (41264, 2575644, 0.64592516),\n",
       " (438, 47003, 0.6459055),\n",
       " (18861, 1206160, 0.6458379),\n",
       " (121674, 7752238, 0.6458379),\n",
       " (119938, 7625635, 0.64560926),\n",
       " (158562, 10456057, 0.6455374),\n",
       " (32894, 2049301, 0.6455355),\n",
       " (7476, 578089, 0.64551634),\n",
       " (27802, 1713804, 0.6454958),\n",
       " (183402, 12366791, 0.6454686),\n",
       " (189194, 12827383, 0.6454686),\n",
       " (160867, 10633991, 0.6454601),\n",
       " (33993, 2115970, 0.64536273),\n",
       " (15355, 1006490, 0.6453627),\n",
       " (39627, 2472398, 0.6452981),\n",
       " (109302, 6861021, 0.64525634),\n",
       " (32365, 2017866, 0.6451025),\n",
       " (35945, 2246437, 0.64506686),\n",
       " (8436, 632629, 0.64504343),\n",
       " (25219, 1559800, 0.644992),\n",
       " (138041, 8934906, 0.6449367),\n",
       " (134380, 8673352, 0.6446562),\n",
       " (196919, 13449328, 0.6445837),\n",
       " (168693, 11214382, 0.6445134),\n",
       " (47374, 2943491, 0.64447486),\n",
       " (129597, 8325791, 0.6444276),\n",
       " (169195, 11249269, 0.6444237),\n",
       " (59451, 3690822, 0.6444216),\n",
       " (18624, 1192762, 0.64439964),\n",
       " (147915, 9658266, 0.6443974),\n",
       " (33832, 2106634, 0.6443162),\n",
       " (150621, 9863796, 0.64427716),\n",
       " (19981, 1268350, 0.6441468),\n",
       " (166150, 11027657, 0.6439075),\n",
       " (28562, 1766321, 0.64390206),\n",
       " (33167, 2064139, 0.6438967),\n",
       " (43338, 2699385, 0.6438967),\n",
       " (84162, 5215889, 0.6437455),\n",
       " (52360, 3254469, 0.6436612),\n",
       " (25983, 1605470, 0.6436587),\n",
       " (30668, 1902672, 0.6434308),\n",
       " (33670, 2095291, 0.6433881),\n",
       " (47248, 2935936, 0.6433881),\n",
       " (55205, 3431995, 0.6433881),\n",
       " (46522, 2895099, 0.643155),\n",
       " (167103, 11093972, 0.6431405),\n",
       " (37551, 2345534, 0.64301586),\n",
       " (21787, 1366503, 0.6429589),\n",
       " (14819, 974674, 0.64295304),\n",
       " (97467, 6068960, 0.6428876),\n",
       " (9581, 689943, 0.6428087),\n",
       " (136119, 8800931, 0.6426914),\n",
       " (28900, 1787683, 0.64266694),\n",
       " (88945, 5519874, 0.6425885),\n",
       " (58458, 3627705, 0.6425066),\n",
       " (137009, 8862999, 0.64247996),\n",
       " (26717, 1648907, 0.6424799),\n",
       " (34102, 2124240, 0.6424799),\n",
       " (175347, 11721910, 0.64245754),\n",
       " (66723, 4128796, 0.64242935),\n",
       " (58221, 3611768, 0.6423786),\n",
       " (191199, 12989029, 0.6423786),\n",
       " (190876, 12964437, 0.6421298),\n",
       " (113297, 7150212, 0.6420475),\n",
       " (45795, 2851724, 0.64199424),\n",
       " (153557, 10084741, 0.64191383),\n",
       " (63953, 3964362, 0.64180875),\n",
       " (73160, 4525654, 0.64168245),\n",
       " (80802, 5012226, 0.64158523),\n",
       " (176256, 11790133, 0.6414859),\n",
       " (69364, 4288688, 0.6413952),\n",
       " (189427, 12846541, 0.6411948),\n",
       " (92525, 5745917, 0.6410128),\n",
       " (63422, 3930634, 0.64087945),\n",
       " (140909, 9141284, 0.6408069),\n",
       " (168549, 11203577, 0.64080685),\n",
       " (27462, 1692056, 0.6408006),\n",
       " (178943, 12009179, 0.6407752),\n",
       " (164950, 10936360, 0.6406996),\n",
       " (175873, 11760852, 0.64068985),\n",
       " (101001, 6296698, 0.640582),\n",
       " (30733, 1906447, 0.6405399),\n",
       " (171045, 11393604, 0.6404837),\n",
       " (195323, 13315244, 0.6404373),\n",
       " (4951, 419295, 0.6404228),\n",
       " (163536, 10830564, 0.6403164),\n",
       " (126325, 8085880, 0.6400893),\n",
       " (5748, 467653, 0.64008474),\n",
       " (31165, 1934223, 0.6400649),\n",
       " (49234, 3060329, 0.6400484),\n",
       " (27679, 1705528, 0.6400144),\n",
       " (68915, 4264276, 0.6398612),\n",
       " (190242, 12913936, 0.6398321),\n",
       " (28125, 1738108, 0.6396935),\n",
       " (80815, 5013170, 0.6394793),\n",
       " (107516, 6737500, 0.63938487),\n",
       " (107890, 6764541, 0.6393678),\n",
       " (112231, 7076430, 0.6393652),\n",
       " (151005, 9892119, 0.63925534),\n",
       " (28707, 1774670, 0.6390015),\n",
       " (151139, 9902180, 0.63891923),\n",
       " (75483, 4673020, 0.6388471),\n",
       " (164316, 10889589, 0.63877606),\n",
       " (137591, 8905186, 0.6387063),\n",
       " (172430, 11500569, 0.63868165),\n",
       " (123683, 7896643, 0.6386566),\n",
       " (108607, 6813700, 0.6385008),\n",
       " (18940, 1210263, 0.6384605),\n",
       " (37200, 2324585, 0.6384605),\n",
       " (40545, 2531071, 0.6384605),\n",
       " (20852, 1314774, 0.6384053),\n",
       " (41379, 2582427, 0.6383842),\n",
       " (172745, 11523175, 0.6383842),\n",
       " (32266, 2012421, 0.6383574),\n",
       " (46495, 2893633, 0.6383277),\n",
       " (126253, 8080797, 0.6383016),\n",
       " (42324, 2639762, 0.63822657),\n",
       " (75767, 4689893, 0.6381235),\n",
       " (7710, 592261, 0.6381223),\n",
       " (129829, 8340742, 0.6379566),\n",
       " (113622, 7172667, 0.63795626),\n",
       " (20692, 1307067, 0.6379249),\n",
       " (63935, 3963065, 0.63785875),\n",
       " (192168, 13063990, 0.63765335),\n",
       " (153749, 10097612, 0.6376109),\n",
       " (47335, 2941441, 0.6375288),\n",
       " (64589, 3999248, 0.63747156),\n",
       " (16925, 1098036, 0.63744986),\n",
       " (94776, 5897567, 0.63743633),\n",
       " (71442, 4417680, 0.6374196),\n",
       " (146461, 9554703, 0.63732827),\n",
       " (15593, 1019312, 0.6373235),\n",
       " (120603, 7672482, 0.63731456),\n",
       " (150762, 9874702, 0.63731456),\n",
       " (34194, 2131112, 0.6372849),\n",
       " (122224, 7793162, 0.6370988),\n",
       " (75805, 4692454, 0.63681173),\n",
       " (51442, 3198675, 0.6367835),\n",
       " (127417, 8166995, 0.6366989),\n",
       " (51047, 3175567, 0.6366627),\n",
       " (9794, 702843, 0.6365931),\n",
       " (132797, 8561325, 0.63657755),\n",
       " (23812, 1477533, 0.63650143),\n",
       " (110385, 6940893, 0.6364337),\n",
       " (51297, 3189906, 0.6363584),\n",
       " (173632, 11594259, 0.6363439),\n",
       " (195662, 13345075, 0.6362709),\n",
       " (133013, 8576296, 0.6362443),\n",
       " (709, 79197, 0.6362143),\n",
       " (165276, 10961581, 0.63620913),\n",
       " (132751, 8558891, 0.6361656),\n",
       " (115524, 7306171, 0.6360954),\n",
       " (89595, 5562259, 0.6360241),\n",
       " (34573, 2155763, 0.63597465),\n",
       " (90722, 5631029, 0.63580126),\n",
       " (197961, 13539455, 0.63567257),\n",
       " (97292, 6057207, 0.6356637),\n",
       " (147566, 9631955, 0.6356425),\n",
       " (70504, 4362351, 0.63562393),\n",
       " (145442, 9478351, 0.6355821),\n",
       " (37934, 2370388, 0.635507),\n",
       " (2286, 227575, 0.6354972),\n",
       " (56810, 3527205, 0.63547903),\n",
       " (148220, 9682279, 0.6354616),\n",
       " (64346, 3985844, 0.63540673),\n",
       " (48714, 3025935, 0.6354052),\n",
       " (25254, 1561617, 0.63536686),\n",
       " (10957, 762742, 0.63536406),\n",
       " (15002, 983640, 0.6353598),\n",
       " (156712, 10315545, 0.63534033),\n",
       " (179070, 12019795, 0.63531464),\n",
       " (67383, 4169643, 0.63531363),\n",
       " (57406, 3561368, 0.63522184),\n",
       " (192006, 13050784, 0.63517153),\n",
       " (159043, 10495770, 0.63514435),\n",
       " (170960, 11386462, 0.63514435),\n",
       " (31144, 1932828, 0.6351118),\n",
       " (24031, 1491482, 0.6351104),\n",
       " (47183, 2931988, 0.6351104),\n",
       " (159625, 10538395, 0.63510406),\n",
       " (71265, 4407267, 0.6350576),\n",
       " (62130, 3852812, 0.63497293),\n",
       " (114594, 7241516, 0.63495135),\n",
       " (91325, 5670109, 0.6348695),\n",
       " (33481, 2082841, 0.6348449),\n",
       " (25697, 1589793, 0.63482505),\n",
       " (159438, 10524326, 0.6348231),\n",
       " ...]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_candidates(question_vec, thread_embeddings, thread_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
